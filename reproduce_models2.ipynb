{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reproduce_models_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgGheJCNKKMi",
        "outputId": "0aa61896-e981-483a-dffb-0ef3669fde24"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import sys\n",
        "#sys.path.append('/content/gdrive/hipsternet-master')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCu02wlCPYnd"
      },
      "source": [
        "sys.path.insert(0,'/content/drive/My Drive/hipsternet-master')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN3bBYMlN5pZ"
      },
      "source": [
        "import hipsternet"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9kb53pqP3zh"
      },
      "source": [
        "import numpy as np\n",
        "import hipsternet.input_data as input_data\n",
        "import hipsternet.neuralnet as nn\n",
        "from hipsternet.solver import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXvo4y6dk_T5"
      },
      "source": [
        "import tensorflow as tf\n",
        "import sympy\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import collections\n",
        "import torch\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from __future__ import print_function\n",
        "\n",
        "np.random.seed(123)\n",
        "\n",
        "# visualization tools\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsz5TNAzlC8t"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "sBqsQBIoazGU",
        "outputId": "a0d31c6c-b02d-4b11-f44c-61e5b4df0bbe"
      },
      "source": [
        "import tensorflow_datasets as tfds \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Generating rotated images: rotated 15%, fill empty pixal with closest color\n",
        "datagen = ImageDataGenerator(rotation_range=15,horizontal_flip=False,fill_mode='nearest')\n",
        "datagen.fit(x_train.reshape(x_train.shape[0],28,28,1))\n",
        "\n",
        "#Print the first rotated image\n",
        "print('Before rotating 15%')\n",
        "plt.imshow(x_train[0])\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "print('After rotating 15%')\n",
        "for X, Y in datagen.flow(x_train.reshape(x_train.shape[0], 28, 28, 1),y_train.reshape(y_train.shape[0], 1),batch_size=32,shuffle=False):\n",
        "        plt.imshow(X[0].reshape(28,28))\n",
        "        plt.colorbar()\n",
        "        plt.show()\n",
        "        break\n",
        "\n",
        "#append new images to training set: image size should be at least 3D, so reshape is necessary here\n",
        "i=0\n",
        "x_train_aug = x_train\n",
        "y_train_aug = y_train\n",
        "for X, Y in datagen.flow(x_train.reshape(x_train.shape[0], 28, 28, 1),y_train.reshape(y_train.shape[0], 1),batch_size=32,shuffle=False):\n",
        "        x_train_aug = np.vstack([x_train_aug, X.reshape(X.shape[0],28,28)])\n",
        "        y_train_aug = np.append(y_train_aug, Y)\n",
        "        i += 1\n",
        "        if (i > x_train.shape[0]/32): break #fix here"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before rotating 15%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAW7ElEQVR4nO3dfbBd1VnH8e/PEIIEtIlpYwppgxhsA7WhXmkcGEoHpZTpTGC0FHTaWNFgS2xR1NKMY1HLDDqFSmtlvEgkzEApLSDRwVKa6fRFS2iIKSSklEiDEC83DSmQvkFy7uMfZ99ybs496+x7z9teN78Ps+ees5/9suYwPKy19lprKyIwM8vVTw26AGZmnXASM7OsOYmZWdacxMwsa05iZpa1I/p5syM1J45ibj9vaXZY+TE/4KV4UZ1c421vnRvP7quVOvahh1+8LyLO7eR+neooiUk6F7gemAX8c0Rckzr+KObyZp3dyS3NLGFTbOz4Gs/uq/Hgfa8pdeysRY8v6PiGHZp2c1LSLOBTwNuBZcDFkpZ1q2BmNhgBjJX8px1JiyV9SdKjkrZL+mCx/ypJuyVtLbbzGs75sKSdkh6T9LZ29+ikJnYasDMinihufDuwEni0g2ua2YAFwYEo15ws4SBwRURskXQs8JCk+4vYxyPiY40HFxWhi4CTgVcDX5R0UkTrAnXSsX8c8FTD96eLfRNIWi1ps6TNB3ixg9uZWb90qyYWESMRsaX4vB/YwSR5osFK4PaIeDEivgPspF5haqnnTycjYjgihiJiaDZzen07M+tQENSi3AYsGK+kFNvqVteVtAQ4FdhU7Foj6WFJ6yTNK/aVqhw16iSJ7QYWN3w/vthnZpkbI0ptwN7xSkqxDU92PUnHAHcCl0fEC8ANwInAcmAEuHa6Ze0kiX0DWCrpBElHUm/HbujgemZWAQHUiFJbGZJmU09gt0bEXQARMRoRtYgYA27k5SbjlCtH005iEXEQWAPcR72de0dEbJ/u9cysOqZQE0uSJOAmYEdEXNewf1HDYRcA24rPG4CLJM2RdAKwFHgwdY+OxolFxL3AvZ1cw8yqJYAD3Vui63Tg3cAjkrYW+9ZSH5K1vLjdLuBSgIjYLukO6qMcDgKXpZ5MQp9H7JtZ9cUUmoptrxXxNWCyGQQtKz8RcTVwddl7OImZ2UQBtYzWSnUSM7MJ6iP28+EkZmaHELVJW4DV5CRmZhPUO/adxMwsU/VxYk5iZpaxMdfEzCxXromZWdYCUcto5XonMTNr4uakmWUrEC/FrEEXozQnMTOboD7Y1c1JM8uYO/bNLFsRohauiZlZxsZcEzOzXNU79vNJDfmU1Mz6wh37Zpa9mseJmVmuPGLfzLI35qeTZpar+gRwJzEzy1QgDnjakZnlKgIPdjWznMmDXc0sX4FrYmaWOXfsm1m2AnlRRDPLV/2VbfmkhnxKamZ94pfnWoXoiPS/4lmvXNDT+z/2p0taxmpHjyXPfe2Je5Lxo9+f/g/tmeuObBnbMvSZ5Ll7az9Ixt/82SuS8V/8kweS8SoLDqMR+5J2AfuBGnAwIoa6USgzG6zDrSb21ojY24XrmFkFROjwqYmZ2cxT79g/fKYdBfAFSQH8U0QMH3qApNXAaoCjOLrD25lZ7+W1xn6nJT0jIt4EvB24TNKZhx4QEcMRMRQRQ7OZ0+HtzKzX6h37KrW1I2mxpC9JelTSdkkfLPbPl3S/pMeLv/OK/ZL0CUk7JT0s6U3t7tFREouI3cXfPcDdwGmdXM/MqqHGT5XaSjgIXBERy4AV1Cs7y4ArgY0RsRTYWHyHeoVoabGtBm5od4NpJzFJcyUdO/4ZOAfYNt3rmVk1jI/Y70ZNLCJGImJL8Xk/sAM4DlgJrC8OWw+cX3xeCdwSdQ8Ar5C0KHWPTvrEFgJ3Sxq/zm0R8fkOrjdjzXr90mQ85sxOxv/vLa9Ixn+0ovWYpvk/mx7v9NU3psdLDdJ//PDYZPxv/+HcZHzTG25rGfvOgR8lz71m9DeS8Vd/NZLx3E3hRSELJG1u+D48Wd84gKQlwKnAJmBhRIwUoWeo5xOoJ7inGk57utg3QgvTTmIR8QTwxumeb2bVFAEHxkonsb1lxodKOga4E7g8Il4oKj/F/SKKh4PT4iEWZjZBvTnZvaeTkmZTT2C3RsRdxe5RSYsiYqRoLo5Pz9gNLG44/fhiX0v5PEc1s76pFfMn223tqF7lugnYERHXNYQ2AKuKz6uAexr2v6d4SrkCeL6h2Tkp18TMbILxIRZdcjrwbuARSVuLfWuBa4A7JF0CPAlcWMTuBc4DdgI/BN7b7gZOYmZ2iO41JyPia9Cyynb2JMcHcNlU7uEkZmZNvMb+YaZ2VnpQ8XU3fyoZP2l26yVjZrIDUUvG//KTv5uMH/GD9AOtX/vsmpaxY3cfTJ47Z296CMbRmzcl4zmrP508fOZOmtkM4+WpzSx7bk6aWba6/HSy55zEzKyJF0U0s2xFiINOYmaWMzcnzSxb7hM7DM157P+S8Yd+vDgZP2n2aDeL01VXjKxIxp/4fvqVbzef+LmWsefH0uO8Fn7iv5LxXprZC+205yRmZtnyODEzy57HiZlZtiLgYPlFEQfOSczMmrg5aWbZcp+YmWUvnMTMLGfu2D/MHBx5Jhn/5N++Mxm/+tz0a9VmPXxMMv7N938yGU/56N5fTsZ3/vrRyXjtueTy5/z2r72/ZWzXB5KncgLfTB9gPRHhPjEzy5qo+emkmeXMfWJmli3PnTSzvEW9XywXTmJm1sRPJ80sW+GOfTPLnZuTNsH8f/l6Mv7Kf/u5ZLz27L5k/ORTfq9lbPuZ65Lnbhh+SzL+quc6W9NLX2891uuE9M9iA5TT08m2dUZJ6yTtkbStYd98SfdLerz4O6+3xTSzfomoJ7EyWxWUafjeDJx7yL4rgY0RsRTYWHw3sxliLFRqq4K2SSwivgIc2p5ZCawvPq8Hzu9yucxsgCLKbVUw3T6xhRExPmnuGWBhqwMlrQZWAxxFeh6emQ1eIMYyejrZcUkjIki8VyEihiNiKCKGZjOn09uZWR9Eya0KppvERiUtAij+7ulekcxsoGZgx/5kNgCris+rgHu6Uxwzq4SMqmJt+8QkfRo4C1gg6WngI8A1wB2SLgGeBC7sZSFnutreZzs6/8ALR0773JN/59Fk/Ls3zEpfYKw27XtbdVWlllVG2yQWERe3CJ3d5bKYWQUEMDbWnSQmaR3wDmBPRJxS7LsK+APgu8VhayPi3iL2YeASoAZ8ICLua3ePfB5BmFl/BBAqt7V3M83jTAE+HhHLi208gS0DLgJOLs75R0ltmgJOYmY2iW6NE2sxzrSVlcDtEfFiRHwH2Amc1u4kJzEza1a+Y3+BpM0N2+qSd1gj6eFiWuP4tMXjgKcajnm62JfkCeBmdogpDZ/YGxFDU7zBDcDfUE+DfwNcC7RexaAN18TMrFkPh1hExGhE1CJiDLiRl5uMu4HFDYceX+xLck1sBnj9h77dMvbeN6QfIv/Lazcm429552XJ+LGfeSAZtwwFRJeeTk5G0qKGaYsXAOMr5GwAbpN0HfBqYCnwYLvrOYmZ2SS6NsRisnGmZ0laTr0utwu4FCAitku6A3gUOAhcFhFtByI6iZlZsy6Nxm8xzvSmxPFXA1dP5R5OYmbWrCJTispwEjOzicYHu2bCSczMmlRlwcMynMTMrFkPn052m5OYmTWRa2LWT7Xnnm8Ze/Z9r0+e+78bfpSMX/nRW5LxD194QTIe//2zLWOLr27zzrac2jQzSYXWCivDSczMDlF6hYpKcBIzs2auiZlZ1sYGXYDynMTMbCKPEzOz3PnppJnlLaMk5vXEzCxrronNcGPf3JGMX/RXf5aM3/qRjyXjW1ekx5GxonXo5LlrkqcuvXEkGT/4xK70vW3a3Jw0s3wFnnZkZplzTczMcubmpJnlzUnMzLLmJGZmuVK4OWlmufPTScvF/HXpNb3WPJZ+7+TPXPN0Mv7pX7ivZWz7e/4hee7rFv9+Mv5Lf5Ueq117/Ilk3FrLqSbWdsS+pHWS9kja1rDvKkm7JW0ttvN6W0wz66sevgG828pMO7oZOHeS/R+PiOXFdm93i2VmAxMv94u126qgbRKLiK8A+/pQFjOrihlWE2tljaSHi+bmvFYHSVotabOkzQd4sYPbmVm/aKzcVgXTTWI3ACcCy4ER4NpWB0bEcEQMRcTQbOZM83ZmZpObVhKLiNGIqEXEGHAjcFp3i2VmAzXTm5OSFjV8vQDY1upYM8tMZh37bceJSfo0cBawQNLTwEeAsyQtp56LdwGX9rCMNkD6z63J+A9/61XJ+K++649axjZ96Prkud966z8n47+z5Jxk/PkzkmFLqUiCKqNtEouIiyfZfVMPymJmVTGTkpiZHV5EdZ48luEkZmYTVai/qwy/KMTMmnXp6WSLaYvzJd0v6fHi77xivyR9QtLOYgzqm8oU1UnMzJp1b4jFzTRPW7wS2BgRS4GNxXeAtwNLi2019fGobTmJmVmTbg2xaDFtcSWwvvi8Hji/Yf8tUfcA8IpDhnNNyn1i1pHa6J5kfOEnWsd//OcHk+cerSOT8RuX/Hsy/o4LLm997bs3Jc897PW2T2xhRIy/j+8ZYGHx+TjgqYbjni72Jd/d5yRmZhPFlJ5OLpC0ueH7cEQMl75VREidPUZwEjOzZuXTyt6IGJri1UclLYqIkaK5OF5d3w0sbjju+GJfkvvEzKxJj6cdbQBWFZ9XAfc07H9P8ZRyBfB8Q7OzJdfEzKxZl/rEWkxbvAa4Q9IlwJPAhcXh9wLnATuBHwLvLXMPJzEzm6iLK1S0mLYIcPYkxwaQfqnDJJzEzGwCkdeIfScxM2viJGYzxtgZy5Px/3nnUcn4Kct3tYy1GwfWzif3nZqMH33P5mTcEpzEzCxrTmJmlq3MVrFwEjOzZk5iZpYzL4poZllzc9LM8lWh17GV4SRmZs2cxKwqNHRKMv7tD7RZs+v09cn4mUe9NOUylfViHEjGH9h3QvoCY23nDtskPGLfzLKnsXyymJOYmU3kPjEzy52bk2aWNycxM8uZa2JmljcnMTPL1tTedjRwTmIZOOKE1ybj//PeV7eMXfWu25Pn/uYxe6dVpm5YO5p+Sc6Xr1+RjM9b//VuFscKuY0Ta/u2I0mLJX1J0qOStkv6YLF/vqT7JT1e/J3X++KaWV9ElNsqoMwr2w4CV0TEMmAFcJmkZcCVwMaIWApsLL6b2QzQ41e2dVXbJBYRIxGxpfi8H9hB/dXiK4HxOSnrgfN7VUgz66OYwlYBU+oTk7QEOBXYBCxseLHlM8DCFuesBlYDHMXR0y2nmfXRjOzYl3QMcCdweUS8IOknsYgIafLKZUQMA8MAP6P5FcndZpaSUxIr0yeGpNnUE9itEXFXsXtU0qIivgjY05simllfBVl17Letiale5boJ2BER1zWENgCrqL+SfBVwT09KOAMcseQ1yfjzv7IoGX/XX38+Gf/DV9yVjPfSFSPpYRBf/8fWwyjm3/xg8tx5Yx5CMShV6bQvo0xz8nTg3cAjkrYW+9ZST153SLoEeBK4sDdFNLO+m0lJLCK+Rn3822TO7m5xzGzQchvs6hH7ZjZRhBdFNLPM5ZPDnMTMrJmbk2aWrwDcnDSzrOWTw5zEyjpi0c+3jO1bNzd57vtO+HIyfvGxo9MqUzes2X1GMr7lhuXJ+ILPbUvG5+/3WK8cuTlpZlnr5tNJSbuA/UANOBgRQ5LmA58BlgC7gAsj4nvTuX6paUdmdhjpzSoWb42I5RExPoWja0t5OYmZ2QT1wa5RautA15bychIzs2ZjJTdYIGlzw7Z6kqsF8AVJDzXESy3lVYb7xMysyRRqWXsbmoitnBERuyW9Crhf0rcag6mlvMpwTczMJupyn1hE7C7+7gHuBk6ji0t5OYmZ2SHqcyfLbO1Imivp2PHPwDnANl5eygs6XMrrsGlOvvS2dI33pT/el4yv/cV7W8bO+ekfTKtM3TJa+1HL2Jkbrkie+7q/+FYyPv+59DivjBYAtano3oKHC4G7i5WgjwBui4jPS/oGXVrK67BJYmZWUhdfnhsRTwBvnGT/s3RpKS8nMTNrVpGlp8twEjOzZvnkMCcxM2umsXx6O53EzGyiIKsnNk5iZjaB6HhKUV85iZlZMyex6tl1fnpc77ff8Nme3ftTz52YjF//5XOScdVavWyq7nUf/U7L2NLRTclza8moHbacxMwsW+4TM7Pc+emkmWUs3Jw0s4wFTmJmlrl8WpNOYmbWzOPEzCxvMymJSVoM3EJ9XaAAhiPieklXAX8AfLc4dG1EtF50a8BOet+Dyfg73vcrfSpJs5NIl60dj/WyroqAWj7tyTI1sYPAFRGxpVih8SFJ9xexj0fEx3pXPDMbiJlUEyveSDJSfN4vaQdwXK8LZmYDlFESm9Ia+5KWAKcC43NZ1kh6WNI6SfNanLN6/HVOB3ixo8KaWR8EMBbltgooncQkHQPcCVweES8ANwAnAsup19Suney8iBiOiKGIGJrNnC4U2cx6KyDGym0VUOrppKTZ1BPYrRFxF0BEjDbEbwT+vSclNLP+CrLq2G9bE1P9NSU3ATsi4rqG/YsaDruA+muYzGwmiCi3VUCZmtjpwLuBRyRtLfatBS6WtJx63t4FXNqTEppZ/1UkQZVR5unk14DJFrSq7JgwM+tEdWpZZXjEvplNFICX4jGzrLkmZmb5mnnTjszscBIQFRkDVoaTmJk1q8ho/DKcxMysmfvEzCxbEX46aWaZc03MzPIVRC2fpTadxMxsovGleDLhJGZmzTIaYjGlRRHNbOYLIMai1FaGpHMlPSZpp6Qru11eJzEzmyi6tyiipFnAp4C3A8uor36zrJvFdXPSzJp0sWP/NGBnRDwBIOl2YCXwaLdu0Ncktp/v7f1ifO7Jhl0LgL39LMMUVLVsVS0XuGzT1c2yvbbTC+zne/d9MT63oOThR0na3PB9OCKGG74fBzzV8P1p4M2dlrFRX5NYRLyy8bukzREx1M8ylFXVslW1XOCyTVfVyhYR5w66DFPhPjEz66XdwOKG78cX+7rGSczMeukbwFJJJ0g6ErgI2NDNGwy6Y3+4/SEDU9WyVbVc4LJNV5XL1pGIOChpDXAfMAtYFxHbu3kPRUZzpMzMDuXmpJllzUnMzLI2kCTW62kInZC0S9IjkrYeMv5lEGVZJ2mPpG0N++ZLul/S48XfeRUq21WSdhe/3VZJ5w2obIslfUnSo5K2S/pgsX+gv12iXJX43XLV9z6xYhrCt4HfoD7w7RvAxRHRtRG8nZC0CxiKiIEPjJR0JvB94JaIOKXY93fAvoi4pvgfwLyI+FBFynYV8P2I+Fi/y3NI2RYBiyJii6RjgYeA84HfZYC/XaJcF1KB3y1Xg6iJ/WQaQkS8BIxPQ7BDRMRXgH2H7F4JrC8+r6f+H0HftShbJUTESERsKT7vB3ZQHzk+0N8uUS7rwCCS2GTTEKr0LzKAL0h6SNLqQRdmEgsjYqT4/AywcJCFmcQaSQ8Xzc2BNHUbSVoCnApsokK/3SHlgor9bjlxx36zMyLiTdRn3V9WNJsqKep9AVUaI3MDcCKwHBgBrh1kYSQdA9wJXB4RLzTGBvnbTVKuSv1uuRlEEuv5NIRORMTu4u8e4G7qzd8qGS36Vsb7WPYMuDw/ERGjEVGL+ksLb2SAv52k2dQTxa0RcVexe+C/3WTlqtLvlqNBJLGeT0OYLklziw5XJM0FzgG2pc/quw3AquLzKuCeAZZlgvEEUbiAAf12kgTcBOyIiOsaQgP97VqVqyq/W64GMmK/eIT897w8DeHqvhdiEpJ+gXrtC+pTsm4bZNkkfRo4i/pSLaPAR4B/Be4AXgM8CVwYEX3vYG9RtrOoN4kC2AVc2tAH1c+ynQF8FXgEGF+5by31/qeB/XaJcl1MBX63XHnakZllzR37ZpY1JzEzy5qTmJllzUnMzLLmJGZmWXMSM7OsOYmZWdb+H71dPbjcA328AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "After rotating 15%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W3D61sza61Z",
        "outputId": "89ca1f7f-f13e-4684-fc51-73d277970777"
      },
      "source": [
        "#Augmented training sets: x_train_aug, y_train_aug\n",
        "#vectorize data into 2-d np array\n",
        "x_train, x_test = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]), x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
        "\n",
        "#normalization: rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "x_train, x_test = x_train/255.0, x_test/255.0\n",
        "print(\"Dimansion of x_train: \", x_train.shape)\n",
        "\n",
        "#reshape and normalize the augmented training set\n",
        "#x_train_aug = x_train_aug.reshape(x_train_aug.shape[0], x_train_aug.shape[1]*x_train_aug.shape[2])\n",
        "#x_train_aug = x_train_aug/255.0\n",
        "#print(\"Dimansion of x_train_aug: \", x_train_aug.shape)\n",
        "\n",
        "#take the first 100 as validation set\n",
        "x_validation = x_train[:100]\n",
        "y_validation = y_train[:100]\n",
        "x_train = x_train[101:]\n",
        "y_train = y_train[101:]\n",
        "\n",
        "\n",
        "#unormalized data\n",
        "#x_train_unormalized = x_train * 255.0\n",
        "#x_test_unormalized = x_test * 255.0\n",
        "#x_validation_unormalized = x_validation * 255.0\n",
        "\n",
        "#At this point x_train, x_test, x_train_unormalized, x_validation_unormalized, x_test_unormalized, x_validation are 2-d np array, y_train, y_test, y_validation are 1-d np array"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dimansion of x_train:  (60000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj9CrRTlrged"
      },
      "source": [
        "# preprocess data, normalization by substracting training mean from training, validation, test datasets\n",
        "def prepro(X_train, X_val, X_test):\n",
        "    mean = np.mean(X_train)\n",
        "    return X_train - mean, X_val - mean, X_test - mean"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIV9nDb1CNJo"
      },
      "source": [
        "Hyper-param tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xexn-q0OCMWh"
      },
      "source": [
        "def tune_hyperparam(model, n_iter, alpha, mb_size, n_experiment, reg, print_after, p_dropout, loss, nonlin, solver_fun, max_norm, x_train, x_val, x_test, y_train, y_val, y_test, candidates, nlayer):\n",
        "    M, D, C = x_train.shape[0], x_train.shape[1], y_train.max() + 1\n",
        "\n",
        "    accuracies = np.array([[0,0,0,0]]) # initiate accuracy array, containing hyper-param candidates composition and corresponding accuracy\n",
        "    accs = np.zeros(n_experiment) # initiate accuracy array for a single set of hyper-param\n",
        "\n",
        "    for max_norm in candidates[0]:\n",
        "      for dropout_rate_input in candidates[1]:\n",
        "        for dropout_rate_hidden in candidates[2]:\n",
        "          # composite the droup out array based on the number of hidden layers\n",
        "          dropoutArray = np.array([dropout_rate_input])\n",
        "          for i in range(1):\n",
        "            dropoutArray = np.append(dropoutArray, [dropout_rate_hidden])\n",
        "\n",
        "          print('Experiment on hyper-parm candidates. max_norm: ', max_norm, 'input drop out rate: ', dropout_rate_input, 'hidden layer drop out rate: ', dropout_rate_hidden)\n",
        "\n",
        "          for k in range(n_experiment):\n",
        "             print('Experiment-{}'.format(k + 1))\n",
        "\n",
        "             # Reset model\n",
        "             if model == 'ff':\n",
        "                net = nn.FeedForwardNet(D, C, H=2048, lam=reg, p_dropout=dropoutArray, loss=loss, nonlin=nonlin, nlayer=nlayer)\n",
        "             elif model == 'cnn':\n",
        "                net = nn.ConvNet(10, C, H=128, lam=1e-3, p_dropout=dropoutArray, loss=loss, nonlin=nonlin)\n",
        "\n",
        "             net = solver_fun(\n",
        "                 net, x_train, y_train, val_set=(x_val, y_val), mb_size=mb_size, alpha=alpha,\n",
        "                 n_iter=n_iter, print_after=print_after, max_norm=max_norm\n",
        "             )\n",
        "\n",
        "             y_pred = net.predict(x_test)\n",
        "             accs[k] = np.mean(y_pred == y_test)\n",
        "\n",
        "          print()\n",
        "          print('Mean accuracy: {:.4f}, std: {:.4f}'.format(accs.mean(), accs.std()))\n",
        "          print()\n",
        "          \n",
        "          accuracies = np.concatenate((accuracies, [[max_norm, dropout_rate_input, dropout_rate_hidden, accs.mean()]]))\n",
        "\n",
        "      \n",
        "    \n",
        "    index = np.argmax(accuracies, axis=0)[3] # index of the best hyper-parm in the accuracies\n",
        "    best_max_norm = accuracies[index][0]\n",
        "    best_dropout_rate_input = accuracies[index][1]\n",
        "    best_dropout_rate_hidden = accuracies[index][2]\n",
        "    best_acc = accuracies[index][3]\n",
        "\n",
        "         \n",
        "    return best_max_norm, best_dropout_rate_input, best_dropout_rate_hidden, best_acc\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HudecacFZKBo"
      },
      "source": [
        "# Train and predict mnist dataset\n",
        "def run_mnist(model, n_iter, alpha, mb_size, n_experiment, reg, print_after, p_dropout, loss, nonlin, solver, max_norm, x_train, x_val, x_test, y_train, y_val, y_test, candidates, nlayer):\n",
        "    M, D, C = x_train.shape[0], x_train.shape[1], y_train.max() + 1\n",
        "  \n",
        "    x_train, x_val, x_test = prepro(x_train, x_val, x_test)\n",
        "    \n",
        "    # A key/value hash table of optimization algorithm, all algorithms use minibatch technique\n",
        "    solvers = dict(\n",
        "        sgd=sgd,                # SGD\n",
        "        momentum=momentum,          # Momentum SGD\n",
        "        nesterov=nesterov,          # Nesterov Momentum\n",
        "        adagrad=adagrad,           # Adagrad\n",
        "        rmsprop=rmsprop,          # RMSprop\n",
        "        adam=adam             # Adam\n",
        "    )\n",
        "    \n",
        "    solver_fun = solvers[solver]\n",
        "    \n",
        "    print()\n",
        "    print('Experimenting on {}'.format(solver))\n",
        "    print()\n",
        "    \n",
        "    if model == 'cnn':\n",
        "        img_shape = (1, 28, 28)\n",
        "        x_train = x_train.reshape(-1, *img_shape)\n",
        "        x_val = x_val.reshape(-1, *img_shape)\n",
        "        x_test = x_test.reshape(-1, *img_shape)\n",
        "\n",
        "    #tune hyper-parameters\n",
        "    best_max_norm, best_dropout_rate_input = 4, 0.85\n",
        "    #train and predict\n",
        "    accs = np.zeros(n_experiment) # initiate accuracy array for a single set of hyper-param\n",
        "    best_dropoutArray = [0.85]\n",
        "\n",
        "    for k in range(n_experiment):\n",
        "        print('Experiment-{}'.format(k + 1))\n",
        "\n",
        "        # Reset model\n",
        "        if model == 'ff':\n",
        "           net = nn.FeedForwardNet(D, C, H=8192, lam=reg, p_dropout=best_dropoutArray, loss=loss, nonlin=nonlin, nlayer=nlayer)\n",
        "        elif model == 'cnn':\n",
        "           net = nn.ConvNet(10, C, H=128, lam=1e-3, p_dropout=best_dropoutArray, loss=loss, nonlin=nonlin)\n",
        "\n",
        "        net = solver_fun(\n",
        "            net, x_train, y_train, val_set=(x_val, y_val), mb_size=mb_size, alpha=alpha,\n",
        "            n_iter=n_iter, print_after=print_after, max_norm=best_max_norm\n",
        "        )\n",
        "\n",
        "        y_pred = net.predict(x_test)\n",
        "        accs[k] = np.mean(y_pred == y_test)\n",
        "\n",
        "    print()\n",
        "    print('Best max_norm: ', best_max_norm, 'best dropout rate for input: ', best_dropout_rate_input, 'and result accuracy is: ', accs.mean())\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzeg1Ba2r_Z9"
      },
      "source": [
        "Dropout NN + max-norm constraint + ReLU + 2 layers + 8192 hidden units (50,000 weight updates) - first trial\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUzfBdDVs2we",
        "outputId": "bd5c8f8c-3217-4be9-8019-b22a6821e242"
      },
      "source": [
        "model = 'ff'\n",
        "n_iter = 50000\n",
        "alpha = 1e-3\n",
        "mb_size = 64\n",
        "n_experiment = 1\n",
        "reg = 1e-5\n",
        "print_after = 100\n",
        "p_dropout = [0.85] #if nlayer=n, len(p_dropout) = n-1\n",
        "loss = 'cross_ent'\n",
        "nonlin = 'relu'\n",
        "solver = 'sgd'\n",
        "max_norm = 4\n",
        "nlayer = 2\n",
        "\n",
        "# Define default candidates\n",
        "candidates = np.array([[3, 3.5, 4],[0.495, 0.5, 0.55], [0.795, 0.8, 0.85]]) # first hyper-param as max-norm, second as drop-out rate for input layer, third as drop-out rate for hidden layers\n",
        "\n",
        "run_mnist(model, n_iter, alpha, mb_size, n_experiment, reg, print_after, p_dropout, loss, nonlin, solver, max_norm, x_train, x_validation, x_test, y_train, y_validation, y_test, candidates, nlayer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Experimenting on sgd\n",
            "\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.9040 validation: 0.790000\n",
            "Iter-200 loss: 1.6473 validation: 0.790000\n",
            "Iter-300 loss: 1.5689 validation: 0.800000\n",
            "Iter-400 loss: 1.3840 validation: 0.800000\n",
            "Iter-500 loss: 1.3390 validation: 0.820000\n",
            "Iter-600 loss: 1.3443 validation: 0.860000\n",
            "Iter-700 loss: 1.2910 validation: 0.850000\n",
            "Iter-800 loss: 1.4011 validation: 0.850000\n",
            "Iter-900 loss: 1.2724 validation: 0.860000\n",
            "Iter-1000 loss: 1.0801 validation: 0.860000\n",
            "Iter-1100 loss: 1.1882 validation: 0.860000\n",
            "Iter-1200 loss: 1.1223 validation: 0.860000\n",
            "Iter-1300 loss: 1.0947 validation: 0.860000\n",
            "Iter-1400 loss: 1.1287 validation: 0.870000\n",
            "Iter-1500 loss: 1.0877 validation: 0.870000\n",
            "Iter-1600 loss: 1.1903 validation: 0.880000\n",
            "Iter-1700 loss: 1.1318 validation: 0.880000\n",
            "Iter-1800 loss: 1.0572 validation: 0.880000\n",
            "Iter-1900 loss: 1.1467 validation: 0.880000\n",
            "Iter-2000 loss: 1.0423 validation: 0.880000\n",
            "Iter-2100 loss: 1.0000 validation: 0.880000\n",
            "Iter-2200 loss: 1.0962 validation: 0.890000\n",
            "Iter-2300 loss: 1.0796 validation: 0.890000\n",
            "Iter-2400 loss: 0.9368 validation: 0.890000\n",
            "Iter-2500 loss: 0.9154 validation: 0.890000\n",
            "Iter-2600 loss: 1.1167 validation: 0.890000\n",
            "Iter-2700 loss: 1.0698 validation: 0.890000\n",
            "Iter-2800 loss: 1.0498 validation: 0.890000\n",
            "Iter-2900 loss: 0.9604 validation: 0.890000\n",
            "Iter-3000 loss: 1.0100 validation: 0.890000\n",
            "Iter-3100 loss: 1.0213 validation: 0.890000\n",
            "Iter-3200 loss: 0.8863 validation: 0.890000\n",
            "Iter-3300 loss: 1.0017 validation: 0.890000\n",
            "Iter-3400 loss: 0.8869 validation: 0.890000\n",
            "Iter-3500 loss: 0.9434 validation: 0.890000\n",
            "Iter-3600 loss: 0.8514 validation: 0.890000\n",
            "Iter-3700 loss: 0.8162 validation: 0.890000\n",
            "Iter-3800 loss: 0.9977 validation: 0.890000\n",
            "Iter-3900 loss: 0.9058 validation: 0.890000\n",
            "Iter-4000 loss: 0.9871 validation: 0.890000\n",
            "Iter-4100 loss: 0.8817 validation: 0.890000\n",
            "Iter-4200 loss: 1.0807 validation: 0.890000\n",
            "Iter-4300 loss: 0.9209 validation: 0.890000\n",
            "Iter-4400 loss: 0.9951 validation: 0.890000\n",
            "Iter-4500 loss: 0.9406 validation: 0.890000\n",
            "Iter-4600 loss: 0.9235 validation: 0.890000\n",
            "Iter-4700 loss: 0.9326 validation: 0.890000\n",
            "Iter-4800 loss: 0.9117 validation: 0.890000\n",
            "Iter-4900 loss: 1.0226 validation: 0.890000\n",
            "Iter-5000 loss: 0.9184 validation: 0.900000\n",
            "Iter-5100 loss: 0.8874 validation: 0.900000\n",
            "Iter-5200 loss: 0.8630 validation: 0.900000\n",
            "Iter-5300 loss: 0.8270 validation: 0.900000\n",
            "Iter-5400 loss: 0.8935 validation: 0.900000\n",
            "Iter-5500 loss: 0.8455 validation: 0.900000\n",
            "Iter-5600 loss: 0.9245 validation: 0.900000\n",
            "Iter-5700 loss: 0.8085 validation: 0.900000\n",
            "Iter-5800 loss: 0.9103 validation: 0.900000\n",
            "Iter-5900 loss: 0.8797 validation: 0.910000\n",
            "Iter-6000 loss: 0.8185 validation: 0.890000\n",
            "Iter-6100 loss: 0.8126 validation: 0.890000\n",
            "Iter-6200 loss: 0.7823 validation: 0.900000\n",
            "Iter-6300 loss: 0.8433 validation: 0.890000\n",
            "Iter-6400 loss: 0.9529 validation: 0.900000\n",
            "Iter-6500 loss: 1.0011 validation: 0.910000\n",
            "Iter-6600 loss: 0.8242 validation: 0.910000\n",
            "Iter-6700 loss: 0.9052 validation: 0.910000\n",
            "Iter-6800 loss: 0.8978 validation: 0.910000\n",
            "Iter-6900 loss: 0.8931 validation: 0.910000\n",
            "Iter-7000 loss: 0.9548 validation: 0.910000\n",
            "Iter-7100 loss: 1.0435 validation: 0.910000\n",
            "Iter-7200 loss: 0.9297 validation: 0.910000\n",
            "Iter-7300 loss: 0.8730 validation: 0.910000\n",
            "Iter-7400 loss: 0.9299 validation: 0.910000\n",
            "Iter-7500 loss: 0.8117 validation: 0.910000\n",
            "Iter-7600 loss: 0.8517 validation: 0.910000\n",
            "Iter-7700 loss: 0.6999 validation: 0.910000\n",
            "Iter-7800 loss: 0.9090 validation: 0.910000\n",
            "Iter-7900 loss: 0.8435 validation: 0.910000\n",
            "Iter-8000 loss: 0.6763 validation: 0.910000\n",
            "Iter-8100 loss: 0.7831 validation: 0.910000\n",
            "Iter-8200 loss: 0.8548 validation: 0.910000\n",
            "Iter-8300 loss: 0.7484 validation: 0.910000\n",
            "Iter-8400 loss: 0.7791 validation: 0.910000\n",
            "Iter-8500 loss: 0.9312 validation: 0.910000\n",
            "Iter-8600 loss: 0.7160 validation: 0.910000\n",
            "Iter-8700 loss: 0.8903 validation: 0.910000\n",
            "Iter-8800 loss: 0.8406 validation: 0.910000\n",
            "Iter-8900 loss: 0.8117 validation: 0.910000\n",
            "Iter-9000 loss: 0.8350 validation: 0.910000\n",
            "Iter-9100 loss: 0.7982 validation: 0.910000\n",
            "Iter-9200 loss: 0.8042 validation: 0.910000\n",
            "Iter-9300 loss: 0.8253 validation: 0.910000\n",
            "Iter-9400 loss: 0.8104 validation: 0.910000\n",
            "Iter-9500 loss: 0.6787 validation: 0.910000\n",
            "Iter-9600 loss: 0.8528 validation: 0.910000\n",
            "Iter-9700 loss: 0.9574 validation: 0.910000\n",
            "Iter-9800 loss: 0.6698 validation: 0.910000\n",
            "Iter-9900 loss: 0.7773 validation: 0.920000\n",
            "Iter-10000 loss: 0.6951 validation: 0.910000\n",
            "Iter-10100 loss: 0.7738 validation: 0.920000\n",
            "Iter-10200 loss: 0.8021 validation: 0.920000\n",
            "Iter-10300 loss: 0.8110 validation: 0.920000\n",
            "Iter-10400 loss: 0.7680 validation: 0.920000\n",
            "Iter-10500 loss: 0.7587 validation: 0.920000\n",
            "Iter-10600 loss: 0.8398 validation: 0.920000\n",
            "Iter-10700 loss: 0.7926 validation: 0.920000\n",
            "Iter-10800 loss: 0.6795 validation: 0.920000\n",
            "Iter-10900 loss: 0.8091 validation: 0.920000\n",
            "Iter-11000 loss: 0.9043 validation: 0.920000\n",
            "Iter-11100 loss: 0.8365 validation: 0.920000\n",
            "Iter-11200 loss: 0.8403 validation: 0.920000\n",
            "Iter-11300 loss: 0.9492 validation: 0.920000\n",
            "Iter-11400 loss: 0.6924 validation: 0.920000\n",
            "Iter-11500 loss: 0.8304 validation: 0.920000\n",
            "Iter-11600 loss: 0.6884 validation: 0.920000\n",
            "Iter-11700 loss: 0.6789 validation: 0.920000\n",
            "Iter-11800 loss: 0.6864 validation: 0.920000\n",
            "Iter-11900 loss: 0.8185 validation: 0.920000\n",
            "Iter-12000 loss: 0.7924 validation: 0.920000\n",
            "Iter-12100 loss: 0.9486 validation: 0.920000\n",
            "Iter-12200 loss: 0.7673 validation: 0.920000\n",
            "Iter-12300 loss: 0.9115 validation: 0.920000\n",
            "Iter-12400 loss: 0.8007 validation: 0.920000\n",
            "Iter-12500 loss: 0.8516 validation: 0.910000\n",
            "Iter-12600 loss: 0.6908 validation: 0.910000\n",
            "Iter-12700 loss: 0.8510 validation: 0.910000\n",
            "Iter-12800 loss: 0.7976 validation: 0.910000\n",
            "Iter-12900 loss: 0.6199 validation: 0.920000\n",
            "Iter-13000 loss: 0.6112 validation: 0.910000\n",
            "Iter-13100 loss: 0.7555 validation: 0.920000\n",
            "Iter-13200 loss: 0.7098 validation: 0.910000\n",
            "Iter-13300 loss: 0.7558 validation: 0.910000\n",
            "Iter-13400 loss: 0.7378 validation: 0.900000\n",
            "Iter-13500 loss: 0.6719 validation: 0.900000\n",
            "Iter-13600 loss: 0.7207 validation: 0.920000\n",
            "Iter-13700 loss: 0.7702 validation: 0.920000\n",
            "Iter-13800 loss: 0.7524 validation: 0.910000\n",
            "Iter-13900 loss: 0.6486 validation: 0.910000\n",
            "Iter-14000 loss: 0.7780 validation: 0.900000\n",
            "Iter-14100 loss: 0.6673 validation: 0.910000\n",
            "Iter-14200 loss: 0.6503 validation: 0.910000\n",
            "Iter-14300 loss: 0.6549 validation: 0.910000\n",
            "Iter-14400 loss: 0.6966 validation: 0.910000\n",
            "Iter-14500 loss: 0.6932 validation: 0.910000\n",
            "Iter-14600 loss: 0.7438 validation: 0.900000\n",
            "Iter-14700 loss: 0.8139 validation: 0.910000\n",
            "Iter-14800 loss: 0.7463 validation: 0.910000\n",
            "Iter-14900 loss: 0.8481 validation: 0.910000\n",
            "Iter-15000 loss: 0.7005 validation: 0.930000\n",
            "Iter-15100 loss: 0.5756 validation: 0.910000\n",
            "Iter-15200 loss: 0.6023 validation: 0.910000\n",
            "Iter-15300 loss: 0.6415 validation: 0.920000\n",
            "Iter-15400 loss: 0.9005 validation: 0.920000\n",
            "Iter-15500 loss: 0.6943 validation: 0.920000\n",
            "Iter-15600 loss: 0.6719 validation: 0.920000\n",
            "Iter-15700 loss: 0.7385 validation: 0.920000\n",
            "Iter-15800 loss: 0.6442 validation: 0.920000\n",
            "Iter-15900 loss: 0.6314 validation: 0.920000\n",
            "Iter-16000 loss: 0.6407 validation: 0.920000\n",
            "Iter-16100 loss: 0.7827 validation: 0.920000\n",
            "Iter-16200 loss: 0.7355 validation: 0.920000\n",
            "Iter-16300 loss: 0.8781 validation: 0.920000\n",
            "Iter-16400 loss: 0.7400 validation: 0.930000\n",
            "Iter-16500 loss: 0.7885 validation: 0.930000\n",
            "Iter-16600 loss: 0.6344 validation: 0.930000\n",
            "Iter-16700 loss: 0.7193 validation: 0.930000\n",
            "Iter-16800 loss: 0.6575 validation: 0.930000\n",
            "Iter-16900 loss: 0.6525 validation: 0.930000\n",
            "Iter-17000 loss: 0.7519 validation: 0.930000\n",
            "Iter-17100 loss: 0.8613 validation: 0.930000\n",
            "Iter-17200 loss: 0.7197 validation: 0.930000\n",
            "Iter-17300 loss: 0.6853 validation: 0.930000\n",
            "Iter-17400 loss: 0.8193 validation: 0.930000\n",
            "Iter-17500 loss: 0.7734 validation: 0.930000\n",
            "Iter-17600 loss: 0.6345 validation: 0.930000\n",
            "Iter-17700 loss: 0.5465 validation: 0.930000\n",
            "Iter-17800 loss: 0.5698 validation: 0.930000\n",
            "Iter-17900 loss: 0.7639 validation: 0.930000\n",
            "Iter-18000 loss: 0.7245 validation: 0.930000\n",
            "Iter-18100 loss: 0.7575 validation: 0.930000\n",
            "Iter-18200 loss: 0.6337 validation: 0.920000\n",
            "Iter-18300 loss: 0.7566 validation: 0.920000\n",
            "Iter-18400 loss: 0.8373 validation: 0.930000\n",
            "Iter-18500 loss: 0.7377 validation: 0.920000\n",
            "Iter-18600 loss: 0.8084 validation: 0.920000\n",
            "Iter-18700 loss: 0.6091 validation: 0.920000\n",
            "Iter-18800 loss: 0.6953 validation: 0.930000\n",
            "Iter-18900 loss: 0.7950 validation: 0.940000\n",
            "Iter-19000 loss: 0.7249 validation: 0.940000\n",
            "Iter-19100 loss: 0.7236 validation: 0.940000\n",
            "Iter-19200 loss: 0.7008 validation: 0.940000\n",
            "Iter-19300 loss: 0.8036 validation: 0.940000\n",
            "Iter-19400 loss: 0.8450 validation: 0.930000\n",
            "Iter-19500 loss: 0.6870 validation: 0.940000\n",
            "Iter-19600 loss: 0.7567 validation: 0.940000\n",
            "Iter-19700 loss: 0.6422 validation: 0.940000\n",
            "Iter-19800 loss: 0.6387 validation: 0.940000\n",
            "Iter-19900 loss: 0.7886 validation: 0.940000\n",
            "Iter-20000 loss: 0.8850 validation: 0.940000\n",
            "Iter-20100 loss: 0.7974 validation: 0.940000\n",
            "Iter-20200 loss: 0.7242 validation: 0.940000\n",
            "Iter-20300 loss: 0.7161 validation: 0.940000\n",
            "Iter-20400 loss: 0.7205 validation: 0.940000\n",
            "Iter-20500 loss: 0.7158 validation: 0.940000\n",
            "Iter-20600 loss: 0.6102 validation: 0.940000\n",
            "Iter-20700 loss: 0.6450 validation: 0.940000\n",
            "Iter-20800 loss: 0.6704 validation: 0.940000\n",
            "Iter-20900 loss: 0.7120 validation: 0.930000\n",
            "Iter-21000 loss: 0.7728 validation: 0.930000\n",
            "Iter-21100 loss: 0.7075 validation: 0.930000\n",
            "Iter-21200 loss: 0.6955 validation: 0.940000\n",
            "Iter-21300 loss: 0.6856 validation: 0.930000\n",
            "Iter-21400 loss: 0.6051 validation: 0.930000\n",
            "Iter-21500 loss: 0.6222 validation: 0.930000\n",
            "Iter-21600 loss: 0.6511 validation: 0.930000\n",
            "Iter-21700 loss: 0.8546 validation: 0.930000\n",
            "Iter-21800 loss: 0.7412 validation: 0.930000\n",
            "Iter-21900 loss: 0.6375 validation: 0.930000\n",
            "Iter-22000 loss: 0.7454 validation: 0.920000\n",
            "Iter-22100 loss: 0.7210 validation: 0.920000\n",
            "Iter-22200 loss: 0.5536 validation: 0.930000\n",
            "Iter-22300 loss: 0.5998 validation: 0.930000\n",
            "Iter-22400 loss: 0.6365 validation: 0.930000\n",
            "Iter-22500 loss: 0.5592 validation: 0.920000\n",
            "Iter-22600 loss: 0.7091 validation: 0.920000\n",
            "Iter-22700 loss: 0.5914 validation: 0.910000\n",
            "Iter-22800 loss: 0.7527 validation: 0.920000\n",
            "Iter-22900 loss: 0.6718 validation: 0.920000\n",
            "Iter-23000 loss: 0.6395 validation: 0.920000\n",
            "Iter-23100 loss: 0.6603 validation: 0.920000\n",
            "Iter-23200 loss: 0.5863 validation: 0.920000\n",
            "Iter-23300 loss: 0.7193 validation: 0.920000\n",
            "Iter-23400 loss: 0.6391 validation: 0.920000\n",
            "Iter-23500 loss: 0.6809 validation: 0.920000\n",
            "Iter-23600 loss: 0.6094 validation: 0.920000\n",
            "Iter-23700 loss: 0.6927 validation: 0.920000\n",
            "Iter-23800 loss: 0.5659 validation: 0.920000\n",
            "Iter-23900 loss: 0.7516 validation: 0.920000\n",
            "Iter-24000 loss: 0.6930 validation: 0.920000\n",
            "Iter-24100 loss: 0.7616 validation: 0.920000\n",
            "Iter-24200 loss: 0.7771 validation: 0.920000\n",
            "Iter-24300 loss: 0.8092 validation: 0.930000\n",
            "Iter-24400 loss: 0.7190 validation: 0.920000\n",
            "Iter-24500 loss: 0.6354 validation: 0.920000\n",
            "Iter-24600 loss: 0.8108 validation: 0.920000\n",
            "Iter-24700 loss: 0.6871 validation: 0.920000\n",
            "Iter-24800 loss: 0.8184 validation: 0.920000\n",
            "Iter-24900 loss: 0.7369 validation: 0.920000\n",
            "Iter-25000 loss: 0.7157 validation: 0.930000\n",
            "Iter-25100 loss: 0.7442 validation: 0.930000\n",
            "Iter-25200 loss: 0.7877 validation: 0.930000\n",
            "Iter-25300 loss: 0.6321 validation: 0.930000\n",
            "Iter-25400 loss: 0.6688 validation: 0.930000\n",
            "Iter-25500 loss: 0.6613 validation: 0.930000\n",
            "Iter-25600 loss: 0.8188 validation: 0.920000\n",
            "Iter-25700 loss: 0.6537 validation: 0.920000\n",
            "Iter-25800 loss: 0.6154 validation: 0.920000\n",
            "Iter-25900 loss: 0.6697 validation: 0.920000\n",
            "Iter-26000 loss: 0.6971 validation: 0.920000\n",
            "Iter-26100 loss: 0.6013 validation: 0.920000\n",
            "Iter-26200 loss: 0.7253 validation: 0.920000\n",
            "Iter-26300 loss: 0.6690 validation: 0.920000\n",
            "Iter-26400 loss: 0.5835 validation: 0.930000\n",
            "Iter-26500 loss: 0.7441 validation: 0.920000\n",
            "Iter-26600 loss: 0.6531 validation: 0.920000\n",
            "Iter-26700 loss: 0.6083 validation: 0.920000\n",
            "Iter-26800 loss: 0.6260 validation: 0.910000\n",
            "Iter-26900 loss: 0.6992 validation: 0.910000\n",
            "Iter-27000 loss: 0.7459 validation: 0.920000\n",
            "Iter-27100 loss: 0.5910 validation: 0.910000\n",
            "Iter-27200 loss: 0.7293 validation: 0.910000\n",
            "Iter-27300 loss: 0.8524 validation: 0.920000\n",
            "Iter-27400 loss: 0.7492 validation: 0.930000\n",
            "Iter-27500 loss: 0.7645 validation: 0.930000\n",
            "Iter-27600 loss: 0.6237 validation: 0.910000\n",
            "Iter-27700 loss: 0.6121 validation: 0.910000\n",
            "Iter-27800 loss: 0.7465 validation: 0.910000\n",
            "Iter-27900 loss: 0.6148 validation: 0.910000\n",
            "Iter-28000 loss: 0.6946 validation: 0.910000\n",
            "Iter-28100 loss: 0.7759 validation: 0.920000\n",
            "Iter-28200 loss: 0.6282 validation: 0.920000\n",
            "Iter-28300 loss: 0.7117 validation: 0.920000\n",
            "Iter-28400 loss: 0.6758 validation: 0.920000\n",
            "Iter-28500 loss: 0.6240 validation: 0.910000\n",
            "Iter-28600 loss: 0.6658 validation: 0.910000\n",
            "Iter-28700 loss: 0.6861 validation: 0.910000\n",
            "Iter-28800 loss: 0.5960 validation: 0.920000\n",
            "Iter-28900 loss: 0.7602 validation: 0.910000\n",
            "Iter-29000 loss: 0.6459 validation: 0.920000\n",
            "Iter-29100 loss: 0.6902 validation: 0.920000\n",
            "Iter-29200 loss: 0.6572 validation: 0.920000\n",
            "Iter-29300 loss: 0.7555 validation: 0.920000\n",
            "Iter-29400 loss: 0.6301 validation: 0.920000\n",
            "Iter-29500 loss: 0.5464 validation: 0.920000\n",
            "Iter-29600 loss: 0.6830 validation: 0.920000\n",
            "Iter-29700 loss: 0.7257 validation: 0.920000\n",
            "Iter-29800 loss: 0.5652 validation: 0.920000\n",
            "Iter-29900 loss: 0.6151 validation: 0.920000\n",
            "Iter-30000 loss: 0.7082 validation: 0.930000\n",
            "Iter-30100 loss: 0.7561 validation: 0.920000\n",
            "Iter-30200 loss: 0.5081 validation: 0.910000\n",
            "Iter-30300 loss: 0.6971 validation: 0.920000\n",
            "Iter-30400 loss: 0.6578 validation: 0.910000\n",
            "Iter-30500 loss: 0.8479 validation: 0.920000\n",
            "Iter-30600 loss: 0.6585 validation: 0.920000\n",
            "Iter-30700 loss: 0.7159 validation: 0.920000\n",
            "Iter-30800 loss: 0.7040 validation: 0.920000\n",
            "Iter-30900 loss: 0.7024 validation: 0.920000\n",
            "Iter-31000 loss: 0.7152 validation: 0.920000\n",
            "Iter-31100 loss: 0.7028 validation: 0.920000\n",
            "Iter-31200 loss: 0.6912 validation: 0.920000\n",
            "Iter-31300 loss: 0.6189 validation: 0.920000\n",
            "Iter-31400 loss: 0.6471 validation: 0.920000\n",
            "Iter-31500 loss: 0.6186 validation: 0.920000\n",
            "Iter-31600 loss: 0.6174 validation: 0.920000\n",
            "Iter-31700 loss: 0.6154 validation: 0.920000\n",
            "Iter-31800 loss: 0.7385 validation: 0.920000\n",
            "Iter-31900 loss: 0.6973 validation: 0.920000\n",
            "Iter-32000 loss: 0.5652 validation: 0.920000\n",
            "Iter-32100 loss: 0.6055 validation: 0.910000\n",
            "Iter-32200 loss: 0.6615 validation: 0.910000\n",
            "Iter-32300 loss: 0.6724 validation: 0.910000\n",
            "Iter-32400 loss: 0.6722 validation: 0.910000\n",
            "Iter-32500 loss: 0.7093 validation: 0.920000\n",
            "Iter-32600 loss: 0.6975 validation: 0.920000\n",
            "Iter-32700 loss: 0.6726 validation: 0.910000\n",
            "Iter-32800 loss: 0.7339 validation: 0.910000\n",
            "Iter-32900 loss: 0.7629 validation: 0.910000\n",
            "Iter-33000 loss: 0.6463 validation: 0.910000\n",
            "Iter-33100 loss: 0.6997 validation: 0.920000\n",
            "Iter-33200 loss: 0.7771 validation: 0.920000\n",
            "Iter-33300 loss: 0.6444 validation: 0.920000\n",
            "Iter-33400 loss: 0.7354 validation: 0.920000\n",
            "Iter-33500 loss: 0.7871 validation: 0.910000\n",
            "Iter-33600 loss: 0.6714 validation: 0.920000\n",
            "Iter-33700 loss: 0.4961 validation: 0.910000\n",
            "Iter-33800 loss: 0.5187 validation: 0.910000\n",
            "Iter-33900 loss: 0.5977 validation: 0.910000\n",
            "Iter-34000 loss: 0.7263 validation: 0.910000\n",
            "Iter-34100 loss: 0.4862 validation: 0.910000\n",
            "Iter-34200 loss: 0.5939 validation: 0.910000\n",
            "Iter-34300 loss: 0.6124 validation: 0.910000\n",
            "Iter-34400 loss: 0.6851 validation: 0.910000\n",
            "Iter-34500 loss: 0.5604 validation: 0.910000\n",
            "Iter-34600 loss: 0.5461 validation: 0.910000\n",
            "Iter-34700 loss: 0.7148 validation: 0.910000\n",
            "Iter-34800 loss: 0.6749 validation: 0.910000\n",
            "Iter-34900 loss: 0.6833 validation: 0.910000\n",
            "Iter-35000 loss: 0.7161 validation: 0.910000\n",
            "Iter-35100 loss: 0.6315 validation: 0.910000\n",
            "Iter-35200 loss: 0.6520 validation: 0.920000\n",
            "Iter-35300 loss: 0.5743 validation: 0.920000\n",
            "Iter-35400 loss: 0.6111 validation: 0.910000\n",
            "Iter-35500 loss: 0.6604 validation: 0.910000\n",
            "Iter-35600 loss: 0.7284 validation: 0.910000\n",
            "Iter-35700 loss: 0.7339 validation: 0.910000\n",
            "Iter-35800 loss: 0.6405 validation: 0.910000\n",
            "Iter-35900 loss: 0.6667 validation: 0.920000\n",
            "Iter-36000 loss: 0.6485 validation: 0.920000\n",
            "Iter-36100 loss: 0.7031 validation: 0.920000\n",
            "Iter-36200 loss: 0.6062 validation: 0.910000\n",
            "Iter-36300 loss: 0.5866 validation: 0.910000\n",
            "Iter-36400 loss: 0.7740 validation: 0.910000\n",
            "Iter-36500 loss: 0.6952 validation: 0.910000\n",
            "Iter-36600 loss: 0.7388 validation: 0.920000\n",
            "Iter-36700 loss: 0.6437 validation: 0.920000\n",
            "Iter-36800 loss: 0.5739 validation: 0.920000\n",
            "Iter-36900 loss: 0.4835 validation: 0.910000\n",
            "Iter-37000 loss: 0.6952 validation: 0.920000\n",
            "Iter-37100 loss: 0.7166 validation: 0.910000\n",
            "Iter-37200 loss: 0.5559 validation: 0.910000\n",
            "Iter-37300 loss: 0.5965 validation: 0.910000\n",
            "Iter-37400 loss: 0.5348 validation: 0.910000\n",
            "Iter-37500 loss: 0.6855 validation: 0.910000\n",
            "Iter-37600 loss: 0.7025 validation: 0.910000\n",
            "Iter-37700 loss: 0.5717 validation: 0.910000\n",
            "Iter-37800 loss: 0.6268 validation: 0.920000\n",
            "Iter-37900 loss: 0.6010 validation: 0.910000\n",
            "Iter-38000 loss: 0.6671 validation: 0.910000\n",
            "Iter-38100 loss: 0.7810 validation: 0.910000\n",
            "Iter-38200 loss: 0.7725 validation: 0.910000\n",
            "Iter-38300 loss: 0.5393 validation: 0.910000\n",
            "Iter-38400 loss: 0.7113 validation: 0.910000\n",
            "Iter-38500 loss: 0.5607 validation: 0.910000\n",
            "Iter-38600 loss: 0.7390 validation: 0.910000\n",
            "Iter-38700 loss: 0.5964 validation: 0.910000\n",
            "Iter-38800 loss: 0.5304 validation: 0.910000\n",
            "Iter-38900 loss: 0.7049 validation: 0.910000\n",
            "Iter-39000 loss: 0.8519 validation: 0.910000\n",
            "Iter-39100 loss: 0.6093 validation: 0.910000\n",
            "Iter-39200 loss: 0.6587 validation: 0.910000\n",
            "Iter-39300 loss: 0.7279 validation: 0.910000\n",
            "Iter-39400 loss: 0.6972 validation: 0.910000\n",
            "Iter-39500 loss: 0.6534 validation: 0.910000\n",
            "Iter-39600 loss: 0.6429 validation: 0.910000\n",
            "Iter-39700 loss: 0.6540 validation: 0.910000\n",
            "Iter-39800 loss: 0.6456 validation: 0.910000\n",
            "Iter-39900 loss: 0.6413 validation: 0.910000\n",
            "Iter-40000 loss: 0.4924 validation: 0.910000\n",
            "Iter-40100 loss: 0.6346 validation: 0.900000\n",
            "Iter-40200 loss: 0.6428 validation: 0.900000\n",
            "Iter-40300 loss: 0.6130 validation: 0.900000\n",
            "Iter-40400 loss: 0.6675 validation: 0.900000\n",
            "Iter-40500 loss: 0.6746 validation: 0.900000\n",
            "Iter-40600 loss: 0.7116 validation: 0.900000\n",
            "Iter-40700 loss: 0.6015 validation: 0.900000\n",
            "Iter-40800 loss: 0.5501 validation: 0.900000\n",
            "Iter-40900 loss: 0.6579 validation: 0.900000\n",
            "Iter-41000 loss: 0.6053 validation: 0.900000\n",
            "Iter-41100 loss: 0.6649 validation: 0.900000\n",
            "Iter-41200 loss: 0.7101 validation: 0.900000\n",
            "Iter-41300 loss: 0.6904 validation: 0.900000\n",
            "Iter-41400 loss: 0.6103 validation: 0.910000\n",
            "Iter-41500 loss: 0.5271 validation: 0.910000\n",
            "Iter-41600 loss: 0.6088 validation: 0.910000\n",
            "Iter-41700 loss: 0.6548 validation: 0.910000\n",
            "Iter-41800 loss: 0.5708 validation: 0.900000\n",
            "Iter-41900 loss: 0.7471 validation: 0.900000\n",
            "Iter-42000 loss: 0.5559 validation: 0.910000\n",
            "Iter-42100 loss: 0.5947 validation: 0.910000\n",
            "Iter-42200 loss: 0.6447 validation: 0.910000\n",
            "Iter-42300 loss: 0.7227 validation: 0.910000\n",
            "Iter-42400 loss: 0.5598 validation: 0.910000\n",
            "Iter-42500 loss: 0.7293 validation: 0.910000\n",
            "Iter-42600 loss: 0.6460 validation: 0.910000\n",
            "Iter-42700 loss: 0.6822 validation: 0.910000\n",
            "Iter-42800 loss: 0.7131 validation: 0.910000\n",
            "Iter-42900 loss: 0.5236 validation: 0.910000\n",
            "Iter-43000 loss: 0.5801 validation: 0.910000\n",
            "Iter-43100 loss: 0.5744 validation: 0.900000\n",
            "Iter-43200 loss: 0.6948 validation: 0.910000\n",
            "Iter-43300 loss: 0.5934 validation: 0.910000\n",
            "Iter-43400 loss: 0.5975 validation: 0.900000\n",
            "Iter-43500 loss: 0.6799 validation: 0.900000\n",
            "Iter-43600 loss: 0.5902 validation: 0.900000\n",
            "Iter-43700 loss: 0.6021 validation: 0.900000\n",
            "Iter-43800 loss: 0.6790 validation: 0.900000\n",
            "Iter-43900 loss: 0.6922 validation: 0.900000\n",
            "Iter-44000 loss: 0.6021 validation: 0.900000\n",
            "Iter-44100 loss: 0.5775 validation: 0.900000\n",
            "Iter-44200 loss: 0.8133 validation: 0.910000\n",
            "Iter-44300 loss: 0.8029 validation: 0.900000\n",
            "Iter-44400 loss: 0.5677 validation: 0.900000\n",
            "Iter-44500 loss: 0.5539 validation: 0.900000\n",
            "Iter-44600 loss: 0.6136 validation: 0.900000\n",
            "Iter-44700 loss: 0.5920 validation: 0.900000\n",
            "Iter-44800 loss: 0.6126 validation: 0.900000\n",
            "Iter-44900 loss: 0.6379 validation: 0.900000\n",
            "Iter-45000 loss: 0.6243 validation: 0.900000\n",
            "Iter-45100 loss: 0.5516 validation: 0.900000\n",
            "Iter-45200 loss: 0.5480 validation: 0.900000\n",
            "Iter-45300 loss: 0.7262 validation: 0.900000\n",
            "Iter-45400 loss: 0.6157 validation: 0.900000\n",
            "Iter-45500 loss: 0.5626 validation: 0.900000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfsZJb2jsaZO"
      },
      "source": [
        "Dropout NN + max-norm constraint + ReLU + 2 layers + 8192 hidden units (50,000 weight updates) - second trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uw5QI7zV9dIG",
        "outputId": "81f3245d-dc39-4096-9f66-2402966fcb4f"
      },
      "source": [
        "model = 'ff'\n",
        "n_iter = 50000\n",
        "alpha = 1e-3\n",
        "mb_size = 64\n",
        "n_experiment = 1\n",
        "reg = 1e-5\n",
        "print_after = 100\n",
        "p_dropout = [0.85] #if nlayer=n, len(p_dropout) = n-1\n",
        "loss = 'cross_ent'\n",
        "nonlin = 'relu'\n",
        "solver = 'sgd'\n",
        "max_norm = 4\n",
        "nlayer = 2\n",
        "\n",
        "# Define default candidates\n",
        "candidates = np.array([[3, 3.5, 4],[0.495, 0.5, 0.55], [0.795, 0.8, 0.85]]) # first hyper-param as max-norm, second as drop-out rate for input layer, third as drop-out rate for hidden layers\n",
        "\n",
        "run_mnist(model, n_iter, alpha, mb_size, n_experiment, reg, print_after, p_dropout, loss, nonlin, solver, max_norm, x_train, x_validation, x_test, y_train, y_validation, y_test, candidates, nlayer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Experimenting on sgd\n",
            "\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.9040 validation: 0.790000\n",
            "Iter-200 loss: 1.6473 validation: 0.790000\n",
            "Iter-300 loss: 1.5689 validation: 0.800000\n",
            "Iter-400 loss: 1.3840 validation: 0.800000\n",
            "Iter-500 loss: 1.3390 validation: 0.820000\n",
            "Iter-600 loss: 1.3443 validation: 0.860000\n",
            "Iter-700 loss: 1.2910 validation: 0.850000\n",
            "Iter-800 loss: 1.4011 validation: 0.850000\n",
            "Iter-900 loss: 1.2724 validation: 0.860000\n",
            "Iter-1000 loss: 1.0801 validation: 0.860000\n",
            "Iter-1100 loss: 1.1882 validation: 0.860000\n",
            "Iter-1200 loss: 1.1223 validation: 0.860000\n",
            "Iter-1300 loss: 1.0947 validation: 0.860000\n",
            "Iter-1400 loss: 1.1287 validation: 0.870000\n",
            "Iter-1500 loss: 1.0877 validation: 0.870000\n",
            "Iter-1600 loss: 1.1903 validation: 0.880000\n",
            "Iter-1700 loss: 1.1318 validation: 0.880000\n",
            "Iter-1800 loss: 1.0572 validation: 0.880000\n",
            "Iter-1900 loss: 1.1467 validation: 0.880000\n",
            "Iter-2000 loss: 1.0423 validation: 0.880000\n",
            "Iter-2100 loss: 1.0000 validation: 0.880000\n",
            "Iter-2200 loss: 1.0962 validation: 0.890000\n",
            "Iter-2300 loss: 1.0796 validation: 0.890000\n",
            "Iter-2400 loss: 0.9368 validation: 0.890000\n",
            "Iter-2500 loss: 0.9154 validation: 0.890000\n",
            "Iter-2600 loss: 1.1167 validation: 0.890000\n",
            "Iter-2700 loss: 1.0698 validation: 0.890000\n",
            "Iter-2800 loss: 1.0498 validation: 0.890000\n",
            "Iter-2900 loss: 0.9604 validation: 0.890000\n",
            "Iter-3000 loss: 1.0100 validation: 0.890000\n",
            "Iter-3100 loss: 1.0213 validation: 0.890000\n",
            "Iter-3200 loss: 0.8863 validation: 0.890000\n",
            "Iter-3300 loss: 1.0017 validation: 0.890000\n",
            "Iter-3400 loss: 0.8869 validation: 0.890000\n",
            "Iter-3500 loss: 0.9434 validation: 0.890000\n",
            "Iter-3600 loss: 0.8514 validation: 0.890000\n",
            "Iter-3700 loss: 0.8162 validation: 0.890000\n",
            "Iter-3800 loss: 0.9977 validation: 0.890000\n",
            "Iter-3900 loss: 0.9058 validation: 0.890000\n",
            "Iter-4000 loss: 0.9871 validation: 0.890000\n",
            "Iter-4100 loss: 0.8817 validation: 0.890000\n",
            "Iter-4200 loss: 1.0807 validation: 0.890000\n",
            "Iter-4300 loss: 0.9209 validation: 0.890000\n",
            "Iter-4400 loss: 0.9951 validation: 0.890000\n",
            "Iter-4500 loss: 0.9406 validation: 0.890000\n",
            "Iter-4600 loss: 0.9235 validation: 0.890000\n",
            "Iter-4700 loss: 0.9326 validation: 0.890000\n",
            "Iter-4800 loss: 0.9117 validation: 0.890000\n",
            "Iter-4900 loss: 1.0226 validation: 0.890000\n",
            "Iter-5000 loss: 0.9184 validation: 0.900000\n",
            "Iter-5100 loss: 0.8874 validation: 0.900000\n",
            "Iter-5200 loss: 0.8630 validation: 0.900000\n",
            "Iter-5300 loss: 0.8270 validation: 0.900000\n",
            "Iter-5400 loss: 0.8935 validation: 0.900000\n",
            "Iter-5500 loss: 0.8455 validation: 0.900000\n",
            "Iter-5600 loss: 0.9245 validation: 0.900000\n",
            "Iter-5700 loss: 0.8085 validation: 0.900000\n",
            "Iter-5800 loss: 0.9103 validation: 0.900000\n",
            "Iter-5900 loss: 0.8797 validation: 0.910000\n",
            "Iter-6000 loss: 0.8185 validation: 0.890000\n",
            "Iter-6100 loss: 0.8126 validation: 0.890000\n",
            "Iter-6200 loss: 0.7823 validation: 0.900000\n",
            "Iter-6300 loss: 0.8433 validation: 0.890000\n",
            "Iter-6400 loss: 0.9529 validation: 0.900000\n",
            "Iter-6500 loss: 1.0011 validation: 0.910000\n",
            "Iter-6600 loss: 0.8242 validation: 0.910000\n",
            "Iter-6700 loss: 0.9052 validation: 0.910000\n",
            "Iter-6800 loss: 0.8978 validation: 0.910000\n",
            "Iter-6900 loss: 0.8931 validation: 0.910000\n",
            "Iter-7000 loss: 0.9548 validation: 0.910000\n",
            "Iter-7100 loss: 1.0435 validation: 0.910000\n",
            "Iter-7200 loss: 0.9297 validation: 0.910000\n",
            "Iter-7300 loss: 0.8730 validation: 0.910000\n",
            "Iter-7400 loss: 0.9299 validation: 0.910000\n",
            "Iter-7500 loss: 0.8117 validation: 0.910000\n",
            "Iter-7600 loss: 0.8517 validation: 0.910000\n",
            "Iter-7700 loss: 0.6999 validation: 0.910000\n",
            "Iter-7800 loss: 0.9090 validation: 0.910000\n",
            "Iter-7900 loss: 0.8435 validation: 0.910000\n",
            "Iter-8000 loss: 0.6763 validation: 0.910000\n",
            "Iter-8100 loss: 0.7831 validation: 0.910000\n",
            "Iter-8200 loss: 0.8548 validation: 0.910000\n",
            "Iter-8300 loss: 0.7484 validation: 0.910000\n",
            "Iter-8400 loss: 0.7791 validation: 0.910000\n",
            "Iter-8500 loss: 0.9312 validation: 0.910000\n",
            "Iter-8600 loss: 0.7160 validation: 0.910000\n",
            "Iter-8700 loss: 0.8903 validation: 0.910000\n",
            "Iter-8800 loss: 0.8406 validation: 0.910000\n",
            "Iter-8900 loss: 0.8117 validation: 0.910000\n",
            "Iter-9000 loss: 0.8350 validation: 0.910000\n",
            "Iter-9100 loss: 0.7982 validation: 0.910000\n",
            "Iter-9200 loss: 0.8042 validation: 0.910000\n",
            "Iter-9300 loss: 0.8253 validation: 0.910000\n",
            "Iter-9400 loss: 0.8104 validation: 0.910000\n",
            "Iter-9500 loss: 0.6787 validation: 0.910000\n",
            "Iter-9600 loss: 0.8528 validation: 0.910000\n",
            "Iter-9700 loss: 0.9574 validation: 0.910000\n",
            "Iter-9800 loss: 0.6698 validation: 0.910000\n",
            "Iter-9900 loss: 0.7773 validation: 0.920000\n",
            "Iter-10000 loss: 0.6951 validation: 0.910000\n",
            "Iter-10100 loss: 0.7738 validation: 0.920000\n",
            "Iter-10200 loss: 0.8021 validation: 0.920000\n",
            "Iter-10300 loss: 0.8110 validation: 0.920000\n",
            "Iter-10400 loss: 0.7680 validation: 0.920000\n",
            "Iter-10500 loss: 0.7587 validation: 0.920000\n",
            "Iter-10600 loss: 0.8398 validation: 0.920000\n",
            "Iter-10700 loss: 0.7926 validation: 0.920000\n",
            "Iter-10800 loss: 0.6795 validation: 0.920000\n",
            "Iter-10900 loss: 0.8091 validation: 0.920000\n",
            "Iter-11000 loss: 0.9043 validation: 0.920000\n",
            "Iter-11100 loss: 0.8365 validation: 0.920000\n",
            "Iter-11200 loss: 0.8403 validation: 0.920000\n",
            "Iter-11300 loss: 0.9492 validation: 0.920000\n",
            "Iter-11400 loss: 0.6924 validation: 0.920000\n",
            "Iter-11500 loss: 0.8304 validation: 0.920000\n",
            "Iter-11600 loss: 0.6884 validation: 0.920000\n",
            "Iter-11700 loss: 0.6789 validation: 0.920000\n",
            "Iter-11800 loss: 0.6864 validation: 0.920000\n",
            "Iter-11900 loss: 0.8185 validation: 0.920000\n",
            "Iter-12000 loss: 0.7924 validation: 0.920000\n",
            "Iter-12100 loss: 0.9486 validation: 0.920000\n",
            "Iter-12200 loss: 0.7673 validation: 0.920000\n",
            "Iter-12300 loss: 0.9115 validation: 0.920000\n",
            "Iter-12400 loss: 0.8007 validation: 0.920000\n",
            "Iter-12500 loss: 0.8516 validation: 0.910000\n",
            "Iter-12600 loss: 0.6908 validation: 0.910000\n",
            "Iter-12700 loss: 0.8510 validation: 0.910000\n",
            "Iter-12800 loss: 0.7976 validation: 0.910000\n",
            "Iter-12900 loss: 0.6199 validation: 0.920000\n",
            "Iter-13000 loss: 0.6112 validation: 0.910000\n",
            "Iter-13100 loss: 0.7555 validation: 0.920000\n",
            "Iter-13200 loss: 0.7098 validation: 0.910000\n",
            "Iter-13300 loss: 0.7558 validation: 0.910000\n",
            "Iter-13400 loss: 0.7378 validation: 0.900000\n",
            "Iter-13500 loss: 0.6719 validation: 0.900000\n",
            "Iter-13600 loss: 0.7207 validation: 0.920000\n",
            "Iter-13700 loss: 0.7702 validation: 0.920000\n",
            "Iter-13800 loss: 0.7524 validation: 0.910000\n",
            "Iter-13900 loss: 0.6486 validation: 0.910000\n",
            "Iter-14000 loss: 0.7780 validation: 0.900000\n",
            "Iter-14100 loss: 0.6673 validation: 0.910000\n",
            "Iter-14200 loss: 0.6503 validation: 0.910000\n",
            "Iter-14300 loss: 0.6549 validation: 0.910000\n",
            "Iter-14400 loss: 0.6966 validation: 0.910000\n",
            "Iter-14500 loss: 0.6932 validation: 0.910000\n",
            "Iter-14600 loss: 0.7438 validation: 0.900000\n",
            "Iter-14700 loss: 0.8139 validation: 0.910000\n",
            "Iter-14800 loss: 0.7463 validation: 0.910000\n",
            "Iter-14900 loss: 0.8481 validation: 0.910000\n",
            "Iter-15000 loss: 0.7005 validation: 0.930000\n",
            "Iter-15100 loss: 0.5756 validation: 0.910000\n",
            "Iter-15200 loss: 0.6023 validation: 0.910000\n",
            "Iter-15300 loss: 0.6415 validation: 0.920000\n",
            "Iter-15400 loss: 0.9005 validation: 0.920000\n",
            "Iter-15500 loss: 0.6943 validation: 0.920000\n",
            "Iter-15600 loss: 0.6719 validation: 0.920000\n",
            "Iter-15700 loss: 0.7385 validation: 0.920000\n",
            "Iter-15800 loss: 0.6442 validation: 0.920000\n",
            "Iter-15900 loss: 0.6314 validation: 0.920000\n",
            "Iter-16000 loss: 0.6407 validation: 0.920000\n",
            "Iter-16100 loss: 0.7827 validation: 0.920000\n",
            "Iter-16200 loss: 0.7355 validation: 0.920000\n",
            "Iter-16300 loss: 0.8781 validation: 0.920000\n",
            "Iter-16400 loss: 0.7400 validation: 0.930000\n",
            "Iter-16500 loss: 0.7885 validation: 0.930000\n",
            "Iter-16600 loss: 0.6344 validation: 0.930000\n",
            "Iter-16700 loss: 0.7193 validation: 0.930000\n",
            "Iter-16800 loss: 0.6575 validation: 0.930000\n",
            "Iter-16900 loss: 0.6525 validation: 0.930000\n",
            "Iter-17000 loss: 0.7519 validation: 0.930000\n",
            "Iter-17100 loss: 0.8613 validation: 0.930000\n",
            "Iter-17200 loss: 0.7197 validation: 0.930000\n",
            "Iter-17300 loss: 0.6853 validation: 0.930000\n",
            "Iter-17400 loss: 0.8193 validation: 0.930000\n",
            "Iter-17500 loss: 0.7734 validation: 0.930000\n",
            "Iter-17600 loss: 0.6345 validation: 0.930000\n",
            "Iter-17700 loss: 0.5465 validation: 0.930000\n",
            "Iter-17800 loss: 0.5698 validation: 0.930000\n",
            "Iter-17900 loss: 0.7639 validation: 0.930000\n",
            "Iter-18000 loss: 0.7245 validation: 0.930000\n",
            "Iter-18100 loss: 0.7575 validation: 0.930000\n",
            "Iter-18200 loss: 0.6337 validation: 0.920000\n",
            "Iter-18300 loss: 0.7566 validation: 0.920000\n",
            "Iter-18400 loss: 0.8373 validation: 0.930000\n",
            "Iter-18500 loss: 0.7377 validation: 0.920000\n",
            "Iter-18600 loss: 0.8084 validation: 0.920000\n",
            "Iter-18700 loss: 0.6091 validation: 0.920000\n",
            "Iter-18800 loss: 0.6953 validation: 0.930000\n",
            "Iter-18900 loss: 0.7950 validation: 0.940000\n",
            "Iter-19000 loss: 0.7249 validation: 0.940000\n",
            "Iter-19100 loss: 0.7236 validation: 0.940000\n",
            "Iter-19200 loss: 0.7008 validation: 0.940000\n",
            "Iter-19300 loss: 0.8036 validation: 0.940000\n",
            "Iter-19400 loss: 0.8450 validation: 0.930000\n",
            "Iter-19500 loss: 0.6870 validation: 0.940000\n",
            "Iter-19600 loss: 0.7567 validation: 0.940000\n",
            "Iter-19700 loss: 0.6422 validation: 0.940000\n",
            "Iter-19800 loss: 0.6387 validation: 0.940000\n",
            "Iter-19900 loss: 0.7886 validation: 0.940000\n",
            "Iter-20000 loss: 0.8850 validation: 0.940000\n",
            "Iter-20100 loss: 0.7974 validation: 0.940000\n",
            "Iter-20200 loss: 0.7242 validation: 0.940000\n",
            "Iter-20300 loss: 0.7161 validation: 0.940000\n",
            "Iter-20400 loss: 0.7205 validation: 0.940000\n",
            "Iter-20500 loss: 0.7158 validation: 0.940000\n",
            "Iter-20600 loss: 0.6102 validation: 0.940000\n",
            "Iter-20700 loss: 0.6450 validation: 0.940000\n",
            "Iter-20800 loss: 0.6704 validation: 0.940000\n",
            "Iter-20900 loss: 0.7120 validation: 0.930000\n",
            "Iter-21000 loss: 0.7728 validation: 0.930000\n",
            "Iter-21100 loss: 0.7075 validation: 0.930000\n",
            "Iter-21200 loss: 0.6955 validation: 0.940000\n",
            "Iter-21300 loss: 0.6856 validation: 0.930000\n",
            "Iter-21400 loss: 0.6051 validation: 0.930000\n",
            "Iter-21500 loss: 0.6222 validation: 0.930000\n",
            "Iter-21600 loss: 0.6511 validation: 0.930000\n",
            "Iter-21700 loss: 0.8546 validation: 0.930000\n",
            "Iter-21800 loss: 0.7412 validation: 0.930000\n",
            "Iter-21900 loss: 0.6375 validation: 0.930000\n",
            "Iter-22000 loss: 0.7454 validation: 0.920000\n",
            "Iter-22100 loss: 0.7210 validation: 0.920000\n",
            "Iter-22200 loss: 0.5536 validation: 0.930000\n",
            "Iter-22300 loss: 0.5998 validation: 0.930000\n",
            "Iter-22400 loss: 0.6365 validation: 0.930000\n",
            "Iter-22500 loss: 0.5592 validation: 0.920000\n",
            "Iter-22600 loss: 0.7091 validation: 0.920000\n",
            "Iter-22700 loss: 0.5914 validation: 0.910000\n",
            "Iter-22800 loss: 0.7527 validation: 0.920000\n",
            "Iter-22900 loss: 0.6718 validation: 0.920000\n",
            "Iter-23000 loss: 0.6395 validation: 0.920000\n",
            "Iter-23100 loss: 0.6603 validation: 0.920000\n",
            "Iter-23200 loss: 0.5863 validation: 0.920000\n",
            "Iter-23300 loss: 0.7193 validation: 0.920000\n",
            "Iter-23400 loss: 0.6391 validation: 0.920000\n",
            "Iter-23500 loss: 0.6809 validation: 0.920000\n",
            "Iter-23600 loss: 0.6094 validation: 0.920000\n",
            "Iter-23700 loss: 0.6927 validation: 0.920000\n",
            "Iter-23800 loss: 0.5659 validation: 0.920000\n",
            "Iter-23900 loss: 0.7516 validation: 0.920000\n",
            "Iter-24000 loss: 0.6930 validation: 0.920000\n",
            "Iter-24100 loss: 0.7616 validation: 0.920000\n",
            "Iter-24200 loss: 0.7771 validation: 0.920000\n",
            "Iter-24300 loss: 0.8092 validation: 0.930000\n",
            "Iter-24400 loss: 0.7190 validation: 0.920000\n",
            "Iter-24500 loss: 0.6354 validation: 0.920000\n",
            "Iter-24600 loss: 0.8108 validation: 0.920000\n",
            "Iter-24700 loss: 0.6871 validation: 0.920000\n",
            "Iter-24800 loss: 0.8184 validation: 0.920000\n",
            "Iter-24900 loss: 0.7369 validation: 0.920000\n",
            "Iter-25000 loss: 0.7157 validation: 0.930000\n",
            "Iter-25100 loss: 0.7442 validation: 0.930000\n",
            "Iter-25200 loss: 0.7877 validation: 0.930000\n",
            "Iter-25300 loss: 0.6321 validation: 0.930000\n",
            "Iter-25400 loss: 0.6688 validation: 0.930000\n",
            "Iter-25500 loss: 0.6613 validation: 0.930000\n",
            "Iter-25600 loss: 0.8188 validation: 0.920000\n",
            "Iter-25700 loss: 0.6537 validation: 0.920000\n",
            "Iter-25800 loss: 0.6154 validation: 0.920000\n",
            "Iter-25900 loss: 0.6697 validation: 0.920000\n",
            "Iter-26000 loss: 0.6971 validation: 0.920000\n",
            "Iter-26100 loss: 0.6013 validation: 0.920000\n",
            "Iter-26200 loss: 0.7253 validation: 0.920000\n",
            "Iter-26300 loss: 0.6690 validation: 0.920000\n",
            "Iter-26400 loss: 0.5835 validation: 0.930000\n",
            "Iter-26500 loss: 0.7441 validation: 0.920000\n",
            "Iter-26600 loss: 0.6531 validation: 0.920000\n",
            "Iter-26700 loss: 0.6083 validation: 0.920000\n",
            "Iter-26800 loss: 0.6260 validation: 0.910000\n",
            "Iter-26900 loss: 0.6992 validation: 0.910000\n",
            "Iter-27000 loss: 0.7459 validation: 0.920000\n",
            "Iter-27100 loss: 0.5910 validation: 0.910000\n",
            "Iter-27200 loss: 0.7293 validation: 0.910000\n",
            "Iter-27300 loss: 0.8524 validation: 0.920000\n",
            "Iter-27400 loss: 0.7492 validation: 0.930000\n",
            "Iter-27500 loss: 0.7645 validation: 0.930000\n",
            "Iter-27600 loss: 0.6237 validation: 0.910000\n",
            "Iter-27700 loss: 0.6121 validation: 0.910000\n",
            "Iter-27800 loss: 0.7465 validation: 0.910000\n",
            "Iter-27900 loss: 0.6148 validation: 0.910000\n",
            "Iter-28000 loss: 0.6946 validation: 0.910000\n",
            "Iter-28100 loss: 0.7759 validation: 0.920000\n",
            "Iter-28200 loss: 0.6282 validation: 0.920000\n",
            "Iter-28300 loss: 0.7117 validation: 0.920000\n",
            "Iter-28400 loss: 0.6758 validation: 0.920000\n",
            "Iter-28500 loss: 0.6240 validation: 0.910000\n",
            "Iter-28600 loss: 0.6658 validation: 0.910000\n",
            "Iter-28700 loss: 0.6861 validation: 0.910000\n",
            "Iter-28800 loss: 0.5960 validation: 0.920000\n",
            "Iter-28900 loss: 0.7602 validation: 0.910000\n",
            "Iter-29000 loss: 0.6459 validation: 0.920000\n",
            "Iter-29100 loss: 0.6902 validation: 0.920000\n",
            "Iter-29200 loss: 0.6572 validation: 0.920000\n",
            "Iter-29300 loss: 0.7555 validation: 0.920000\n",
            "Iter-29400 loss: 0.6301 validation: 0.920000\n",
            "Iter-29500 loss: 0.5464 validation: 0.920000\n",
            "Iter-29600 loss: 0.6830 validation: 0.920000\n",
            "Iter-29700 loss: 0.7257 validation: 0.920000\n",
            "Iter-29800 loss: 0.5652 validation: 0.920000\n",
            "Iter-29900 loss: 0.6151 validation: 0.920000\n",
            "Iter-30000 loss: 0.7082 validation: 0.930000\n",
            "Iter-30100 loss: 0.7561 validation: 0.920000\n",
            "Iter-30200 loss: 0.5081 validation: 0.910000\n",
            "Iter-30300 loss: 0.6971 validation: 0.920000\n",
            "Iter-30400 loss: 0.6578 validation: 0.910000\n",
            "Iter-30500 loss: 0.8479 validation: 0.920000\n",
            "Iter-30600 loss: 0.6585 validation: 0.920000\n",
            "Iter-30700 loss: 0.7159 validation: 0.920000\n",
            "Iter-30800 loss: 0.7040 validation: 0.920000\n",
            "Iter-30900 loss: 0.7024 validation: 0.920000\n",
            "Iter-31000 loss: 0.7152 validation: 0.920000\n",
            "Iter-31100 loss: 0.7028 validation: 0.920000\n",
            "Iter-31200 loss: 0.6912 validation: 0.920000\n",
            "Iter-31300 loss: 0.6189 validation: 0.920000\n",
            "Iter-31400 loss: 0.6471 validation: 0.920000\n",
            "Iter-31500 loss: 0.6186 validation: 0.920000\n",
            "Iter-31600 loss: 0.6174 validation: 0.920000\n",
            "Iter-31700 loss: 0.6154 validation: 0.920000\n",
            "Iter-31800 loss: 0.7385 validation: 0.920000\n",
            "Iter-31900 loss: 0.6973 validation: 0.920000\n",
            "Iter-32000 loss: 0.5652 validation: 0.920000\n",
            "Iter-32100 loss: 0.6055 validation: 0.910000\n",
            "Iter-32200 loss: 0.6615 validation: 0.910000\n",
            "Iter-32300 loss: 0.6724 validation: 0.910000\n",
            "Iter-32400 loss: 0.6722 validation: 0.910000\n",
            "Iter-32500 loss: 0.7093 validation: 0.920000\n",
            "Iter-32600 loss: 0.6975 validation: 0.920000\n",
            "Iter-32700 loss: 0.6726 validation: 0.910000\n",
            "Iter-32800 loss: 0.7339 validation: 0.910000\n",
            "Iter-32900 loss: 0.7629 validation: 0.910000\n",
            "Iter-33000 loss: 0.6463 validation: 0.910000\n",
            "Iter-33100 loss: 0.6997 validation: 0.920000\n",
            "Iter-33200 loss: 0.7771 validation: 0.920000\n",
            "Iter-33300 loss: 0.6444 validation: 0.920000\n",
            "Iter-33400 loss: 0.7354 validation: 0.920000\n",
            "Iter-33500 loss: 0.7871 validation: 0.910000\n",
            "Iter-33600 loss: 0.6714 validation: 0.920000\n",
            "Iter-33700 loss: 0.4961 validation: 0.910000\n",
            "Iter-33800 loss: 0.5187 validation: 0.910000\n",
            "Iter-33900 loss: 0.5977 validation: 0.910000\n",
            "Iter-34000 loss: 0.7263 validation: 0.910000\n",
            "Iter-34100 loss: 0.4862 validation: 0.910000\n",
            "Iter-34200 loss: 0.5939 validation: 0.910000\n",
            "Iter-34300 loss: 0.6124 validation: 0.910000\n",
            "Iter-34400 loss: 0.6851 validation: 0.910000\n",
            "Iter-34500 loss: 0.5604 validation: 0.910000\n",
            "Iter-34600 loss: 0.5461 validation: 0.910000\n",
            "Iter-34700 loss: 0.7148 validation: 0.910000\n",
            "Iter-34800 loss: 0.6749 validation: 0.910000\n",
            "Iter-34900 loss: 0.6833 validation: 0.910000\n",
            "Iter-35000 loss: 0.7161 validation: 0.910000\n",
            "Iter-35100 loss: 0.6315 validation: 0.910000\n",
            "Iter-35200 loss: 0.6520 validation: 0.920000\n",
            "Iter-35300 loss: 0.5743 validation: 0.920000\n",
            "Iter-35400 loss: 0.6111 validation: 0.910000\n",
            "Iter-35500 loss: 0.6604 validation: 0.910000\n",
            "Iter-35600 loss: 0.7284 validation: 0.910000\n",
            "Iter-35700 loss: 0.7339 validation: 0.910000\n",
            "Iter-35800 loss: 0.6405 validation: 0.910000\n",
            "Iter-35900 loss: 0.6667 validation: 0.920000\n",
            "Iter-36000 loss: 0.6485 validation: 0.920000\n",
            "Iter-36100 loss: 0.7031 validation: 0.920000\n",
            "Iter-36200 loss: 0.6062 validation: 0.910000\n",
            "Iter-36300 loss: 0.5866 validation: 0.910000\n",
            "Iter-36400 loss: 0.7740 validation: 0.910000\n",
            "Iter-36500 loss: 0.6952 validation: 0.910000\n",
            "Iter-36600 loss: 0.7388 validation: 0.920000\n",
            "Iter-36700 loss: 0.6437 validation: 0.920000\n",
            "Iter-36800 loss: 0.5739 validation: 0.920000\n",
            "Iter-36900 loss: 0.4835 validation: 0.910000\n",
            "Iter-37000 loss: 0.6952 validation: 0.920000\n",
            "Iter-37100 loss: 0.7166 validation: 0.910000\n",
            "Iter-37200 loss: 0.5559 validation: 0.910000\n",
            "Iter-37300 loss: 0.5965 validation: 0.910000\n",
            "Iter-37400 loss: 0.5348 validation: 0.910000\n",
            "Iter-37500 loss: 0.6855 validation: 0.910000\n",
            "Iter-37600 loss: 0.7025 validation: 0.910000\n",
            "Iter-37700 loss: 0.5717 validation: 0.910000\n",
            "Iter-37800 loss: 0.6268 validation: 0.920000\n",
            "Iter-37900 loss: 0.6010 validation: 0.910000\n",
            "Iter-38000 loss: 0.6671 validation: 0.910000\n",
            "Iter-38100 loss: 0.7810 validation: 0.910000\n",
            "Iter-38200 loss: 0.7725 validation: 0.910000\n",
            "Iter-38300 loss: 0.5393 validation: 0.910000\n",
            "Iter-38400 loss: 0.7113 validation: 0.910000\n",
            "Iter-38500 loss: 0.5607 validation: 0.910000\n",
            "Iter-38600 loss: 0.7390 validation: 0.910000\n",
            "Iter-38700 loss: 0.5964 validation: 0.910000\n",
            "Iter-38800 loss: 0.5304 validation: 0.910000\n",
            "Iter-38900 loss: 0.7049 validation: 0.910000\n",
            "Iter-39000 loss: 0.8519 validation: 0.910000\n",
            "Iter-39100 loss: 0.6093 validation: 0.910000\n",
            "Iter-39200 loss: 0.6587 validation: 0.910000\n",
            "Iter-39300 loss: 0.7279 validation: 0.910000\n",
            "Iter-39400 loss: 0.6972 validation: 0.910000\n",
            "Iter-39500 loss: 0.6534 validation: 0.910000\n",
            "Iter-39600 loss: 0.6429 validation: 0.910000\n",
            "Iter-39700 loss: 0.6540 validation: 0.910000\n",
            "Iter-39800 loss: 0.6456 validation: 0.910000\n",
            "Iter-39900 loss: 0.6413 validation: 0.910000\n",
            "Iter-40000 loss: 0.4924 validation: 0.910000\n",
            "Iter-40100 loss: 0.6346 validation: 0.900000\n",
            "Iter-40200 loss: 0.6428 validation: 0.900000\n",
            "Iter-40300 loss: 0.6130 validation: 0.900000\n",
            "Iter-40400 loss: 0.6675 validation: 0.900000\n",
            "Iter-40500 loss: 0.6746 validation: 0.900000\n",
            "Iter-40600 loss: 0.7116 validation: 0.900000\n",
            "Iter-40700 loss: 0.6015 validation: 0.900000\n",
            "Iter-40800 loss: 0.5501 validation: 0.900000\n",
            "Iter-40900 loss: 0.6579 validation: 0.900000\n",
            "Iter-41000 loss: 0.6053 validation: 0.900000\n",
            "Iter-41100 loss: 0.6649 validation: 0.900000\n",
            "Iter-41200 loss: 0.7101 validation: 0.900000\n",
            "Iter-41300 loss: 0.6904 validation: 0.900000\n",
            "Iter-41400 loss: 0.6103 validation: 0.910000\n",
            "Iter-41500 loss: 0.5271 validation: 0.910000\n",
            "Iter-41600 loss: 0.6088 validation: 0.910000\n",
            "Iter-41700 loss: 0.6548 validation: 0.910000\n",
            "Iter-41800 loss: 0.5708 validation: 0.900000\n",
            "Iter-41900 loss: 0.7471 validation: 0.900000\n",
            "Iter-42000 loss: 0.5559 validation: 0.910000\n",
            "Iter-42100 loss: 0.5947 validation: 0.910000\n",
            "Iter-42200 loss: 0.6447 validation: 0.910000\n",
            "Iter-42300 loss: 0.7227 validation: 0.910000\n",
            "Iter-42400 loss: 0.5598 validation: 0.910000\n",
            "Iter-42500 loss: 0.7293 validation: 0.910000\n",
            "Iter-42600 loss: 0.6460 validation: 0.910000\n",
            "Iter-42700 loss: 0.6822 validation: 0.910000\n",
            "Iter-42800 loss: 0.7131 validation: 0.910000\n",
            "Iter-42900 loss: 0.5236 validation: 0.910000\n",
            "Iter-43000 loss: 0.5801 validation: 0.910000\n",
            "Iter-43100 loss: 0.5744 validation: 0.900000\n",
            "Iter-43200 loss: 0.6948 validation: 0.910000\n",
            "Iter-43300 loss: 0.5934 validation: 0.910000\n",
            "Iter-43400 loss: 0.5975 validation: 0.900000\n",
            "Iter-43500 loss: 0.6799 validation: 0.900000\n",
            "Iter-43600 loss: 0.5902 validation: 0.900000\n",
            "Iter-43700 loss: 0.6021 validation: 0.900000\n",
            "Iter-43800 loss: 0.6790 validation: 0.900000\n",
            "Iter-43900 loss: 0.6922 validation: 0.900000\n",
            "Iter-44000 loss: 0.6021 validation: 0.900000\n",
            "Iter-44100 loss: 0.5775 validation: 0.900000\n",
            "Iter-44200 loss: 0.8133 validation: 0.910000\n",
            "Iter-44300 loss: 0.8029 validation: 0.900000\n",
            "Iter-44400 loss: 0.5677 validation: 0.900000\n",
            "Iter-44500 loss: 0.5539 validation: 0.900000\n",
            "Iter-44600 loss: 0.6136 validation: 0.900000\n",
            "Iter-44700 loss: 0.5920 validation: 0.900000\n",
            "Iter-44800 loss: 0.6126 validation: 0.900000\n",
            "Iter-44900 loss: 0.6379 validation: 0.900000\n",
            "Iter-45000 loss: 0.6243 validation: 0.900000\n",
            "Iter-45100 loss: 0.5516 validation: 0.900000\n",
            "Iter-45200 loss: 0.5480 validation: 0.900000\n",
            "Iter-45300 loss: 0.7262 validation: 0.900000\n",
            "Iter-45400 loss: 0.6157 validation: 0.900000\n",
            "Iter-45500 loss: 0.5626 validation: 0.900000\n",
            "Iter-45600 loss: 0.5251 validation: 0.900000\n",
            "Iter-45700 loss: 0.5861 validation: 0.900000\n",
            "Iter-45800 loss: 0.8020 validation: 0.900000\n",
            "Iter-45900 loss: 0.7770 validation: 0.900000\n",
            "Iter-46000 loss: 0.6700 validation: 0.900000\n",
            "Iter-46100 loss: 0.7365 validation: 0.900000\n",
            "Iter-46200 loss: 0.5607 validation: 0.900000\n",
            "Iter-46300 loss: 0.6180 validation: 0.900000\n",
            "Iter-46400 loss: 0.5586 validation: 0.900000\n",
            "Iter-46500 loss: 0.5728 validation: 0.900000\n",
            "Iter-46600 loss: 0.5809 validation: 0.900000\n",
            "Iter-46700 loss: 0.7085 validation: 0.900000\n",
            "Iter-46800 loss: 0.6605 validation: 0.900000\n",
            "Iter-46900 loss: 0.6321 validation: 0.900000\n",
            "Iter-47000 loss: 0.6670 validation: 0.900000\n",
            "Iter-47100 loss: 0.7140 validation: 0.900000\n",
            "Iter-47200 loss: 0.6650 validation: 0.900000\n",
            "Iter-47300 loss: 0.7080 validation: 0.900000\n",
            "Iter-47400 loss: 0.5537 validation: 0.900000\n",
            "Iter-47500 loss: 0.5865 validation: 0.900000\n",
            "Iter-47600 loss: 0.5812 validation: 0.900000\n",
            "Iter-47700 loss: 0.6589 validation: 0.900000\n",
            "Iter-47800 loss: 0.5573 validation: 0.900000\n",
            "Iter-47900 loss: 0.5690 validation: 0.900000\n",
            "Iter-48000 loss: 0.6269 validation: 0.900000\n",
            "Iter-48100 loss: 0.5532 validation: 0.900000\n",
            "Iter-48200 loss: 0.6229 validation: 0.900000\n",
            "Iter-48300 loss: 0.5331 validation: 0.900000\n",
            "Iter-48400 loss: 0.7945 validation: 0.900000\n",
            "Iter-48500 loss: 0.6206 validation: 0.900000\n",
            "Iter-48600 loss: 0.6378 validation: 0.900000\n",
            "Iter-48700 loss: 0.4658 validation: 0.900000\n",
            "Iter-48800 loss: 0.5648 validation: 0.900000\n",
            "Iter-48900 loss: 0.5813 validation: 0.900000\n",
            "Iter-49000 loss: 0.5780 validation: 0.900000\n",
            "Iter-49100 loss: 0.5754 validation: 0.900000\n",
            "Iter-49200 loss: 0.5207 validation: 0.900000\n",
            "Iter-49300 loss: 0.5542 validation: 0.900000\n",
            "Iter-49400 loss: 0.6400 validation: 0.900000\n",
            "Iter-49500 loss: 0.6289 validation: 0.900000\n",
            "Iter-49600 loss: 0.7036 validation: 0.900000\n",
            "Iter-49700 loss: 0.6995 validation: 0.900000\n",
            "Iter-49800 loss: 0.6216 validation: 0.900000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lysvds1wK2mE"
      },
      "source": [
        "Dropout NN + max-norm constraint + ReLU + 3 layers + 1024 hidden units (100,000 weight updates)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmQUBQJ_segS",
        "outputId": "8a1b5bfd-8305-47d3-b0f5-2f97f518845b"
      },
      "source": [
        "model = 'ff'\n",
        "n_iter = 100000\n",
        "alpha = 1e-3\n",
        "mb_size = 64\n",
        "n_experiment = 1\n",
        "reg = 1e-5\n",
        "print_after = 100\n",
        "p_dropout = [0.5,0.8] #if nlayer=n, len(p_dropout) = n-1\n",
        "loss = 'cross_ent'\n",
        "nonlin = 'relu'\n",
        "solver = 'sgd'\n",
        "max_norm = 4\n",
        "nlayer = 3\n",
        "\n",
        "# Define default candidates\n",
        "candidates = np.array([[3, 3.5, 4],[0.795, 0.8, 0.85],[0.495, 0.5, 0.55]]) # first hyper-param as max-norm, second as drop-out rate for input layer, third as drop-out rate for hidden layers\n",
        "\n",
        "run_mnist(model, n_iter, alpha, mb_size, n_experiment, reg, print_after, p_dropout, loss, nonlin, solver, max_norm, x_train, x_validation, x_test, y_train, y_validation, y_test, candidates, nlayer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Experimenting on sgd\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.795 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.9418 validation: 0.800000\n",
            "Iter-200 loss: 1.6889 validation: 0.820000\n",
            "Iter-300 loss: 1.6383 validation: 0.820000\n",
            "Iter-400 loss: 1.4346 validation: 0.850000\n",
            "Iter-500 loss: 1.4446 validation: 0.860000\n",
            "\n",
            "Mean accuracy: 0.8596, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.795 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.9109 validation: 0.850000\n",
            "Iter-200 loss: 1.7611 validation: 0.860000\n",
            "Iter-300 loss: 1.5916 validation: 0.860000\n",
            "Iter-400 loss: 1.4576 validation: 0.860000\n",
            "Iter-500 loss: 1.4488 validation: 0.880000\n",
            "\n",
            "Mean accuracy: 0.8616, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.795 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.9078 validation: 0.790000\n",
            "Iter-200 loss: 1.6824 validation: 0.820000\n",
            "Iter-300 loss: 1.5460 validation: 0.820000\n",
            "Iter-400 loss: 1.5342 validation: 0.850000\n",
            "Iter-500 loss: 1.5115 validation: 0.880000\n",
            "\n",
            "Mean accuracy: 0.8619, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.8 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.9127 validation: 0.850000\n",
            "Iter-200 loss: 1.7082 validation: 0.850000\n",
            "Iter-300 loss: 1.5493 validation: 0.850000\n",
            "Iter-400 loss: 1.5245 validation: 0.870000\n",
            "Iter-500 loss: 1.4088 validation: 0.880000\n",
            "\n",
            "Mean accuracy: 0.8605, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.8 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.8807 validation: 0.810000\n",
            "Iter-200 loss: 1.7027 validation: 0.830000\n",
            "Iter-300 loss: 1.6165 validation: 0.860000\n",
            "Iter-400 loss: 1.5187 validation: 0.870000\n",
            "Iter-500 loss: 1.3814 validation: 0.870000\n",
            "\n",
            "Mean accuracy: 0.8559, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.8 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.8851 validation: 0.810000\n",
            "Iter-200 loss: 1.6557 validation: 0.840000\n",
            "Iter-300 loss: 1.5987 validation: 0.850000\n",
            "Iter-400 loss: 1.4854 validation: 0.890000\n",
            "Iter-500 loss: 1.4852 validation: 0.900000\n",
            "\n",
            "Mean accuracy: 0.8587, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.85 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.9157 validation: 0.830000\n",
            "Iter-200 loss: 1.6755 validation: 0.860000\n",
            "Iter-300 loss: 1.5482 validation: 0.870000\n",
            "Iter-400 loss: 1.3996 validation: 0.880000\n",
            "Iter-500 loss: 1.4660 validation: 0.890000\n",
            "\n",
            "Mean accuracy: 0.8637, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.85 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.8302 validation: 0.820000\n",
            "Iter-200 loss: 1.6973 validation: 0.840000\n",
            "Iter-300 loss: 1.5709 validation: 0.840000\n",
            "Iter-400 loss: 1.4809 validation: 0.870000\n",
            "Iter-500 loss: 1.3574 validation: 0.880000\n",
            "\n",
            "Mean accuracy: 0.8642, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.0 input drop out rate:  0.85 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.8882 validation: 0.810000\n",
            "Iter-200 loss: 1.6781 validation: 0.840000\n",
            "Iter-300 loss: 1.5425 validation: 0.840000\n",
            "Iter-400 loss: 1.5077 validation: 0.850000\n",
            "Iter-500 loss: 1.4407 validation: 0.860000\n",
            "\n",
            "Mean accuracy: 0.8572, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.795 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7664 validation: 0.840000\n",
            "Iter-200 loss: 1.5346 validation: 0.860000\n",
            "Iter-300 loss: 1.3878 validation: 0.850000\n",
            "Iter-400 loss: 1.2986 validation: 0.860000\n",
            "Iter-500 loss: 1.3494 validation: 0.890000\n",
            "\n",
            "Mean accuracy: 0.8674, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.795 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7636 validation: 0.790000\n",
            "Iter-200 loss: 1.5765 validation: 0.850000\n",
            "Iter-300 loss: 1.3941 validation: 0.850000\n",
            "Iter-400 loss: 1.3108 validation: 0.880000\n",
            "Iter-500 loss: 1.2011 validation: 0.900000\n",
            "\n",
            "Mean accuracy: 0.8733, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.795 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.8350 validation: 0.790000\n",
            "Iter-200 loss: 1.5087 validation: 0.830000\n",
            "Iter-300 loss: 1.3333 validation: 0.850000\n",
            "Iter-400 loss: 1.3176 validation: 0.890000\n",
            "Iter-500 loss: 1.2964 validation: 0.890000\n",
            "\n",
            "Mean accuracy: 0.8657, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.8 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.8091 validation: 0.800000\n",
            "Iter-200 loss: 1.5374 validation: 0.840000\n",
            "Iter-300 loss: 1.3685 validation: 0.860000\n",
            "Iter-400 loss: 1.3533 validation: 0.890000\n",
            "Iter-500 loss: 1.2444 validation: 0.880000\n",
            "\n",
            "Mean accuracy: 0.8665, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.8 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7569 validation: 0.810000\n",
            "Iter-200 loss: 1.5975 validation: 0.840000\n",
            "Iter-300 loss: 1.3671 validation: 0.870000\n",
            "Iter-400 loss: 1.3107 validation: 0.880000\n",
            "Iter-500 loss: 1.2452 validation: 0.880000\n",
            "\n",
            "Mean accuracy: 0.8714, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.8 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7596 validation: 0.790000\n",
            "Iter-200 loss: 1.5189 validation: 0.810000\n",
            "Iter-300 loss: 1.3717 validation: 0.850000\n",
            "Iter-400 loss: 1.3182 validation: 0.870000\n",
            "Iter-500 loss: 1.2521 validation: 0.890000\n",
            "\n",
            "Mean accuracy: 0.8696, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.85 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7807 validation: 0.810000\n",
            "Iter-200 loss: 1.5365 validation: 0.830000\n",
            "Iter-300 loss: 1.3737 validation: 0.860000\n",
            "Iter-400 loss: 1.2665 validation: 0.880000\n",
            "Iter-500 loss: 1.2472 validation: 0.900000\n",
            "\n",
            "Mean accuracy: 0.8705, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.85 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.8128 validation: 0.830000\n",
            "Iter-200 loss: 1.4799 validation: 0.850000\n",
            "Iter-300 loss: 1.3851 validation: 0.890000\n",
            "Iter-400 loss: 1.3569 validation: 0.890000\n",
            "Iter-500 loss: 1.2734 validation: 0.900000\n",
            "\n",
            "Mean accuracy: 0.8749, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  3.5 input drop out rate:  0.85 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7735 validation: 0.820000\n",
            "Iter-200 loss: 1.5132 validation: 0.860000\n",
            "Iter-300 loss: 1.3785 validation: 0.840000\n",
            "Iter-400 loss: 1.2930 validation: 0.880000\n",
            "Iter-500 loss: 1.1709 validation: 0.900000\n",
            "\n",
            "Mean accuracy: 0.8778, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.795 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7020 validation: 0.830000\n",
            "Iter-200 loss: 1.3588 validation: 0.820000\n",
            "Iter-300 loss: 1.1295 validation: 0.850000\n",
            "Iter-400 loss: 1.1438 validation: 0.900000\n",
            "Iter-500 loss: 1.0967 validation: 0.910000\n",
            "\n",
            "Mean accuracy: 0.8767, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.795 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.6776 validation: 0.820000\n",
            "Iter-200 loss: 1.3671 validation: 0.860000\n",
            "Iter-300 loss: 1.2217 validation: 0.870000\n",
            "Iter-400 loss: 1.1507 validation: 0.880000\n",
            "Iter-500 loss: 1.1136 validation: 0.900000\n",
            "\n",
            "Mean accuracy: 0.8721, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.795 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.6499 validation: 0.820000\n",
            "Iter-200 loss: 1.3562 validation: 0.850000\n",
            "Iter-300 loss: 1.2650 validation: 0.880000\n",
            "Iter-400 loss: 1.1991 validation: 0.880000\n",
            "Iter-500 loss: 1.1295 validation: 0.880000\n",
            "\n",
            "Mean accuracy: 0.8724, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.8 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.6869 validation: 0.810000\n",
            "Iter-200 loss: 1.3614 validation: 0.860000\n",
            "Iter-300 loss: 1.3235 validation: 0.870000\n",
            "Iter-400 loss: 1.1610 validation: 0.870000\n",
            "Iter-500 loss: 1.0057 validation: 0.900000\n",
            "\n",
            "Mean accuracy: 0.8746, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.8 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7245 validation: 0.820000\n",
            "Iter-200 loss: 1.3939 validation: 0.850000\n",
            "Iter-300 loss: 1.2675 validation: 0.880000\n",
            "Iter-400 loss: 1.0768 validation: 0.900000\n",
            "Iter-500 loss: 1.0864 validation: 0.910000\n",
            "\n",
            "Mean accuracy: 0.8790, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.8 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7089 validation: 0.850000\n",
            "Iter-200 loss: 1.4251 validation: 0.860000\n",
            "Iter-300 loss: 1.2075 validation: 0.860000\n",
            "Iter-400 loss: 1.1226 validation: 0.880000\n",
            "Iter-500 loss: 1.0866 validation: 0.890000\n",
            "\n",
            "Mean accuracy: 0.8793, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.85 hidden layer drop out rate:  0.495\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.6267 validation: 0.820000\n",
            "Iter-200 loss: 1.3140 validation: 0.860000\n",
            "Iter-300 loss: 1.0842 validation: 0.890000\n",
            "Iter-400 loss: 1.1303 validation: 0.890000\n",
            "Iter-500 loss: 1.1270 validation: 0.910000\n",
            "\n",
            "Mean accuracy: 0.8826, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.85 hidden layer drop out rate:  0.5\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.5914 validation: 0.850000\n",
            "Iter-200 loss: 1.3413 validation: 0.880000\n",
            "Iter-300 loss: 1.3622 validation: 0.890000\n",
            "Iter-400 loss: 1.1032 validation: 0.910000\n",
            "Iter-500 loss: 0.9983 validation: 0.920000\n",
            "\n",
            "Mean accuracy: 0.8852, std: 0.0000\n",
            "\n",
            "Experiment on hyper-parm candidates. max_norm:  4.0 input drop out rate:  0.85 hidden layer drop out rate:  0.55\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.7157 validation: 0.830000\n",
            "Iter-200 loss: 1.5110 validation: 0.840000\n",
            "Iter-300 loss: 1.1746 validation: 0.880000\n",
            "Iter-400 loss: 1.1120 validation: 0.890000\n",
            "Iter-500 loss: 1.0423 validation: 0.890000\n",
            "\n",
            "Mean accuracy: 0.8736, std: 0.0000\n",
            "\n",
            "Experiment-1\n",
            "Iter-100 loss: 1.5996 validation: 0.830000\n",
            "Iter-200 loss: 1.3933 validation: 0.860000\n",
            "Iter-300 loss: 1.2065 validation: 0.850000\n",
            "Iter-400 loss: 1.0745 validation: 0.910000\n",
            "Iter-500 loss: 0.9967 validation: 0.920000\n",
            "Iter-600 loss: 0.9587 validation: 0.910000\n",
            "Iter-700 loss: 0.8759 validation: 0.920000\n",
            "Iter-800 loss: 0.9923 validation: 0.940000\n",
            "Iter-900 loss: 0.8901 validation: 0.940000\n",
            "Iter-1000 loss: 0.8192 validation: 0.950000\n",
            "Iter-1100 loss: 0.8368 validation: 0.950000\n",
            "Iter-1200 loss: 0.8619 validation: 0.950000\n",
            "Iter-1300 loss: 0.7496 validation: 0.950000\n",
            "Iter-1400 loss: 0.8444 validation: 0.950000\n",
            "Iter-1500 loss: 0.7356 validation: 0.950000\n",
            "Iter-1600 loss: 0.6936 validation: 0.950000\n",
            "Iter-1700 loss: 0.8805 validation: 0.950000\n",
            "Iter-1800 loss: 0.8515 validation: 0.950000\n",
            "Iter-1900 loss: 0.7741 validation: 0.950000\n",
            "Iter-2000 loss: 0.7119 validation: 0.950000\n",
            "Iter-2100 loss: 0.7012 validation: 0.950000\n",
            "Iter-2200 loss: 0.6598 validation: 0.950000\n",
            "Iter-2300 loss: 0.6753 validation: 0.950000\n",
            "Iter-2400 loss: 0.7750 validation: 0.950000\n",
            "Iter-2500 loss: 0.6176 validation: 0.950000\n",
            "Iter-2600 loss: 0.6833 validation: 0.950000\n",
            "Iter-2700 loss: 0.5740 validation: 0.950000\n",
            "Iter-2800 loss: 0.6860 validation: 0.950000\n",
            "Iter-2900 loss: 0.6462 validation: 0.950000\n",
            "Iter-3000 loss: 0.5180 validation: 0.950000\n",
            "Iter-3100 loss: 0.7113 validation: 0.950000\n",
            "Iter-3200 loss: 0.5956 validation: 0.950000\n",
            "Iter-3300 loss: 0.6710 validation: 0.950000\n",
            "Iter-3400 loss: 0.6256 validation: 0.950000\n",
            "Iter-3500 loss: 0.5774 validation: 0.950000\n",
            "Iter-3600 loss: 0.5663 validation: 0.960000\n",
            "Iter-3700 loss: 0.5773 validation: 0.950000\n",
            "Iter-3800 loss: 0.5690 validation: 0.960000\n",
            "Iter-3900 loss: 0.6799 validation: 0.960000\n",
            "Iter-4000 loss: 0.5395 validation: 0.950000\n",
            "Iter-4100 loss: 0.5749 validation: 0.950000\n",
            "Iter-4200 loss: 0.5806 validation: 0.960000\n",
            "Iter-4300 loss: 0.5430 validation: 0.950000\n",
            "Iter-4400 loss: 0.6122 validation: 0.950000\n",
            "Iter-4500 loss: 0.5376 validation: 0.960000\n",
            "Iter-4600 loss: 0.5446 validation: 0.960000\n",
            "Iter-4700 loss: 0.5463 validation: 0.950000\n",
            "Iter-4800 loss: 0.4898 validation: 0.960000\n",
            "Iter-4900 loss: 0.5477 validation: 0.960000\n",
            "Iter-5000 loss: 0.6204 validation: 0.960000\n",
            "Iter-5100 loss: 0.4775 validation: 0.960000\n",
            "Iter-5200 loss: 0.4265 validation: 0.960000\n",
            "Iter-5300 loss: 0.4736 validation: 0.960000\n",
            "Iter-5400 loss: 0.5710 validation: 0.960000\n",
            "Iter-5500 loss: 0.5408 validation: 0.960000\n",
            "Iter-5600 loss: 0.5308 validation: 0.960000\n",
            "Iter-5700 loss: 0.4891 validation: 0.950000\n",
            "Iter-5800 loss: 0.5591 validation: 0.960000\n",
            "Iter-5900 loss: 0.4976 validation: 0.960000\n",
            "Iter-6000 loss: 0.4244 validation: 0.960000\n",
            "Iter-6100 loss: 0.5834 validation: 0.970000\n",
            "Iter-6200 loss: 0.4807 validation: 0.960000\n",
            "Iter-6300 loss: 0.4025 validation: 0.970000\n",
            "Iter-6400 loss: 0.5592 validation: 0.960000\n",
            "Iter-6500 loss: 0.4761 validation: 0.960000\n",
            "Iter-6600 loss: 0.3767 validation: 0.970000\n",
            "Iter-6700 loss: 0.4498 validation: 0.960000\n",
            "Iter-6800 loss: 0.4523 validation: 0.970000\n",
            "Iter-6900 loss: 0.4396 validation: 0.970000\n",
            "Iter-7000 loss: 0.5024 validation: 0.960000\n",
            "Iter-7100 loss: 0.5238 validation: 0.960000\n",
            "Iter-7200 loss: 0.4214 validation: 0.970000\n",
            "Iter-7300 loss: 0.4653 validation: 0.960000\n",
            "Iter-7400 loss: 0.4231 validation: 0.960000\n",
            "Iter-7500 loss: 0.4424 validation: 0.960000\n",
            "Iter-7600 loss: 0.4790 validation: 0.970000\n",
            "Iter-7700 loss: 0.4681 validation: 0.960000\n",
            "Iter-7800 loss: 0.4950 validation: 0.960000\n",
            "Iter-7900 loss: 0.5521 validation: 0.970000\n",
            "Iter-8000 loss: 0.4051 validation: 0.970000\n",
            "Iter-8100 loss: 0.4605 validation: 0.970000\n",
            "Iter-8200 loss: 0.4004 validation: 0.960000\n",
            "Iter-8300 loss: 0.4984 validation: 0.970000\n",
            "Iter-8400 loss: 0.4525 validation: 0.970000\n",
            "Iter-8500 loss: 0.4629 validation: 0.970000\n",
            "Iter-8600 loss: 0.3774 validation: 0.970000\n",
            "Iter-8700 loss: 0.3662 validation: 0.970000\n",
            "Iter-8800 loss: 0.4947 validation: 0.970000\n",
            "Iter-8900 loss: 0.4008 validation: 0.970000\n",
            "Iter-9000 loss: 0.3787 validation: 0.970000\n",
            "Iter-9100 loss: 0.4623 validation: 0.970000\n",
            "Iter-9200 loss: 0.3765 validation: 0.970000\n",
            "Iter-9300 loss: 0.3452 validation: 0.970000\n",
            "Iter-9400 loss: 0.4412 validation: 0.970000\n",
            "Iter-9500 loss: 0.4725 validation: 0.970000\n",
            "Iter-9600 loss: 0.3844 validation: 0.970000\n",
            "Iter-9700 loss: 0.6043 validation: 0.970000\n",
            "Iter-9800 loss: 0.4542 validation: 0.970000\n",
            "Iter-9900 loss: 0.3518 validation: 0.970000\n",
            "Iter-10000 loss: 0.5114 validation: 0.970000\n",
            "Iter-10100 loss: 0.3775 validation: 0.970000\n",
            "Iter-10200 loss: 0.3221 validation: 0.970000\n",
            "Iter-10300 loss: 0.3331 validation: 0.970000\n",
            "Iter-10400 loss: 0.3240 validation: 0.970000\n",
            "Iter-10500 loss: 0.3326 validation: 0.970000\n",
            "Iter-10600 loss: 0.3331 validation: 0.970000\n",
            "Iter-10700 loss: 0.3923 validation: 0.970000\n",
            "Iter-10800 loss: 0.3485 validation: 0.970000\n",
            "Iter-10900 loss: 0.4094 validation: 0.970000\n",
            "Iter-11000 loss: 0.3770 validation: 0.970000\n",
            "Iter-11100 loss: 0.2915 validation: 0.970000\n",
            "Iter-11200 loss: 0.3713 validation: 0.970000\n",
            "Iter-11300 loss: 0.3601 validation: 0.970000\n",
            "Iter-11400 loss: 0.3820 validation: 0.970000\n",
            "Iter-11500 loss: 0.4102 validation: 0.970000\n",
            "Iter-11600 loss: 0.3796 validation: 0.970000\n",
            "Iter-11700 loss: 0.3436 validation: 0.970000\n",
            "Iter-11800 loss: 0.3893 validation: 0.970000\n",
            "Iter-11900 loss: 0.3936 validation: 0.970000\n",
            "Iter-12000 loss: 0.3491 validation: 0.970000\n",
            "Iter-12100 loss: 0.3518 validation: 0.970000\n",
            "Iter-12200 loss: 0.3261 validation: 0.970000\n",
            "Iter-12300 loss: 0.3660 validation: 0.970000\n",
            "Iter-12400 loss: 0.4001 validation: 0.970000\n",
            "Iter-12500 loss: 0.2807 validation: 0.970000\n",
            "Iter-12600 loss: 0.3358 validation: 0.970000\n",
            "Iter-12700 loss: 0.3100 validation: 0.970000\n",
            "Iter-12800 loss: 0.3566 validation: 0.970000\n",
            "Iter-12900 loss: 0.3919 validation: 0.970000\n",
            "Iter-13000 loss: 0.2792 validation: 0.970000\n",
            "Iter-13100 loss: 0.3053 validation: 0.970000\n",
            "Iter-13200 loss: 0.3118 validation: 0.970000\n",
            "Iter-13300 loss: 0.3867 validation: 0.970000\n",
            "Iter-13400 loss: 0.3732 validation: 0.970000\n",
            "Iter-13500 loss: 0.2627 validation: 0.970000\n",
            "Iter-13600 loss: 0.3131 validation: 0.970000\n",
            "Iter-13700 loss: 0.2504 validation: 0.970000\n",
            "Iter-13800 loss: 0.4268 validation: 0.970000\n",
            "Iter-13900 loss: 0.3272 validation: 0.970000\n",
            "Iter-14000 loss: 0.3545 validation: 0.970000\n",
            "Iter-14100 loss: 0.3015 validation: 0.970000\n",
            "Iter-14200 loss: 0.3506 validation: 0.970000\n",
            "Iter-14300 loss: 0.3993 validation: 0.970000\n",
            "Iter-14400 loss: 0.4415 validation: 0.970000\n",
            "Iter-14500 loss: 0.3220 validation: 0.970000\n",
            "Iter-14600 loss: 0.2552 validation: 0.970000\n",
            "Iter-14700 loss: 0.3514 validation: 0.970000\n",
            "Iter-14800 loss: 0.2894 validation: 0.970000\n",
            "Iter-14900 loss: 0.2794 validation: 0.970000\n",
            "Iter-15000 loss: 0.3071 validation: 0.970000\n",
            "Iter-15100 loss: 0.3156 validation: 0.970000\n",
            "Iter-15200 loss: 0.2162 validation: 0.970000\n",
            "Iter-15300 loss: 0.3174 validation: 0.970000\n",
            "Iter-15400 loss: 0.3515 validation: 0.970000\n",
            "Iter-15500 loss: 0.2859 validation: 0.970000\n",
            "Iter-15600 loss: 0.3907 validation: 0.970000\n",
            "Iter-15700 loss: 0.3029 validation: 0.970000\n",
            "Iter-15800 loss: 0.2882 validation: 0.970000\n",
            "Iter-15900 loss: 0.2979 validation: 0.970000\n",
            "Iter-16000 loss: 0.3173 validation: 0.970000\n",
            "Iter-16100 loss: 0.3833 validation: 0.970000\n",
            "Iter-16200 loss: 0.2802 validation: 0.970000\n",
            "Iter-16300 loss: 0.3469 validation: 0.970000\n",
            "Iter-16400 loss: 0.3008 validation: 0.970000\n",
            "Iter-16500 loss: 0.3964 validation: 0.970000\n",
            "Iter-16600 loss: 0.3144 validation: 0.970000\n",
            "Iter-16700 loss: 0.3562 validation: 0.970000\n",
            "Iter-16800 loss: 0.2634 validation: 0.970000\n",
            "Iter-16900 loss: 0.2234 validation: 0.970000\n",
            "Iter-17000 loss: 0.4045 validation: 0.970000\n",
            "Iter-17100 loss: 0.2011 validation: 0.970000\n",
            "Iter-17200 loss: 0.2396 validation: 0.970000\n",
            "Iter-17300 loss: 0.3067 validation: 0.970000\n",
            "Iter-17400 loss: 0.3549 validation: 0.970000\n",
            "Iter-17500 loss: 0.2105 validation: 0.970000\n",
            "Iter-17600 loss: 0.4180 validation: 0.970000\n",
            "Iter-17700 loss: 0.2543 validation: 0.970000\n",
            "Iter-17800 loss: 0.2911 validation: 0.970000\n",
            "Iter-17900 loss: 0.2079 validation: 0.970000\n",
            "Iter-18000 loss: 0.2176 validation: 0.970000\n",
            "Iter-18100 loss: 0.2827 validation: 0.970000\n",
            "Iter-18200 loss: 0.2087 validation: 0.970000\n",
            "Iter-18300 loss: 0.3114 validation: 0.970000\n",
            "Iter-18400 loss: 0.2808 validation: 0.970000\n",
            "Iter-18500 loss: 0.2649 validation: 0.970000\n",
            "Iter-18600 loss: 0.2361 validation: 0.970000\n",
            "Iter-18700 loss: 0.2967 validation: 0.970000\n",
            "Iter-18800 loss: 0.2456 validation: 0.970000\n",
            "Iter-18900 loss: 0.2783 validation: 0.970000\n",
            "Iter-19000 loss: 0.2508 validation: 0.970000\n",
            "Iter-19100 loss: 0.2237 validation: 0.970000\n",
            "Iter-19200 loss: 0.3081 validation: 0.970000\n",
            "Iter-19300 loss: 0.2239 validation: 0.970000\n",
            "Iter-19400 loss: 0.2648 validation: 0.970000\n",
            "Iter-19500 loss: 0.1899 validation: 0.970000\n",
            "Iter-19600 loss: 0.2431 validation: 0.970000\n",
            "Iter-19700 loss: 0.2072 validation: 0.970000\n",
            "Iter-19800 loss: 0.3564 validation: 0.970000\n",
            "Iter-19900 loss: 0.2683 validation: 0.970000\n",
            "Iter-20000 loss: 0.2388 validation: 0.970000\n",
            "Iter-20100 loss: 0.2526 validation: 0.970000\n",
            "Iter-20200 loss: 0.2856 validation: 0.970000\n",
            "Iter-20300 loss: 0.2683 validation: 0.970000\n",
            "Iter-20400 loss: 0.2355 validation: 0.970000\n",
            "Iter-20500 loss: 0.2052 validation: 0.970000\n",
            "Iter-20600 loss: 0.2395 validation: 0.970000\n",
            "Iter-20700 loss: 0.3176 validation: 0.970000\n",
            "Iter-20800 loss: 0.2348 validation: 0.970000\n",
            "Iter-20900 loss: 0.2646 validation: 0.970000\n",
            "Iter-21000 loss: 0.2226 validation: 0.970000\n",
            "Iter-21100 loss: 0.2726 validation: 0.970000\n",
            "Iter-21200 loss: 0.2462 validation: 0.970000\n",
            "Iter-21300 loss: 0.2877 validation: 0.970000\n",
            "Iter-21400 loss: 0.2352 validation: 0.970000\n",
            "Iter-21500 loss: 0.2793 validation: 0.970000\n",
            "Iter-21600 loss: 0.3302 validation: 0.970000\n",
            "Iter-21700 loss: 0.2492 validation: 0.970000\n",
            "Iter-21800 loss: 0.2609 validation: 0.970000\n",
            "Iter-21900 loss: 0.2884 validation: 0.970000\n",
            "Iter-22000 loss: 0.2722 validation: 0.970000\n",
            "Iter-22100 loss: 0.2610 validation: 0.970000\n",
            "Iter-22200 loss: 0.2570 validation: 0.970000\n",
            "Iter-22300 loss: 0.2325 validation: 0.970000\n",
            "Iter-22400 loss: 0.2435 validation: 0.970000\n",
            "Iter-22500 loss: 0.2336 validation: 0.970000\n",
            "Iter-22600 loss: 0.1709 validation: 0.970000\n",
            "Iter-22700 loss: 0.2696 validation: 0.970000\n",
            "Iter-22800 loss: 0.3220 validation: 0.970000\n",
            "Iter-22900 loss: 0.1989 validation: 0.970000\n",
            "Iter-23000 loss: 0.2372 validation: 0.970000\n",
            "Iter-23100 loss: 0.1963 validation: 0.970000\n",
            "Iter-23200 loss: 0.2252 validation: 0.970000\n",
            "Iter-23300 loss: 0.2205 validation: 0.970000\n",
            "Iter-23400 loss: 0.2047 validation: 0.970000\n",
            "Iter-23500 loss: 0.3209 validation: 0.970000\n",
            "Iter-23600 loss: 0.2265 validation: 0.970000\n",
            "Iter-23700 loss: 0.1877 validation: 0.970000\n",
            "Iter-23800 loss: 0.2368 validation: 0.970000\n",
            "Iter-23900 loss: 0.2337 validation: 0.970000\n",
            "Iter-24000 loss: 0.2213 validation: 0.970000\n",
            "Iter-24100 loss: 0.2691 validation: 0.970000\n",
            "Iter-24200 loss: 0.1770 validation: 0.970000\n",
            "Iter-24300 loss: 0.2430 validation: 0.970000\n",
            "Iter-24400 loss: 0.1975 validation: 0.970000\n",
            "Iter-24500 loss: 0.2375 validation: 0.970000\n",
            "Iter-24600 loss: 0.1959 validation: 0.970000\n",
            "Iter-24700 loss: 0.2189 validation: 0.970000\n",
            "Iter-24800 loss: 0.1974 validation: 0.970000\n",
            "Iter-24900 loss: 0.3011 validation: 0.970000\n",
            "Iter-25000 loss: 0.2785 validation: 0.970000\n",
            "Iter-25100 loss: 0.3439 validation: 0.970000\n",
            "Iter-25200 loss: 0.2356 validation: 0.970000\n",
            "Iter-25300 loss: 0.2425 validation: 0.970000\n",
            "Iter-25400 loss: 0.2395 validation: 0.970000\n",
            "Iter-25500 loss: 0.1776 validation: 0.970000\n",
            "Iter-25600 loss: 0.2716 validation: 0.970000\n",
            "Iter-25700 loss: 0.1797 validation: 0.970000\n",
            "Iter-25800 loss: 0.2403 validation: 0.970000\n",
            "Iter-25900 loss: 0.2126 validation: 0.970000\n",
            "Iter-26000 loss: 0.2043 validation: 0.970000\n",
            "Iter-26100 loss: 0.1757 validation: 0.970000\n",
            "Iter-26200 loss: 0.3275 validation: 0.970000\n",
            "Iter-26300 loss: 0.3020 validation: 0.970000\n",
            "Iter-26400 loss: 0.2268 validation: 0.970000\n",
            "Iter-26500 loss: 0.3119 validation: 0.970000\n",
            "Iter-26600 loss: 0.2372 validation: 0.970000\n",
            "Iter-26700 loss: 0.2126 validation: 0.970000\n",
            "Iter-26800 loss: 0.1975 validation: 0.970000\n",
            "Iter-26900 loss: 0.2279 validation: 0.970000\n",
            "Iter-27000 loss: 0.2105 validation: 0.970000\n",
            "Iter-27100 loss: 0.1991 validation: 0.970000\n",
            "Iter-27200 loss: 0.2840 validation: 0.970000\n",
            "Iter-27300 loss: 0.2180 validation: 0.970000\n",
            "Iter-27400 loss: 0.2458 validation: 0.970000\n",
            "Iter-27500 loss: 0.2325 validation: 0.970000\n",
            "Iter-27600 loss: 0.2298 validation: 0.970000\n",
            "Iter-27700 loss: 0.2405 validation: 0.970000\n",
            "Iter-27800 loss: 0.2023 validation: 0.970000\n",
            "Iter-27900 loss: 0.3288 validation: 0.970000\n",
            "Iter-28000 loss: 0.2385 validation: 0.970000\n",
            "Iter-28100 loss: 0.1934 validation: 0.970000\n",
            "Iter-28200 loss: 0.1582 validation: 0.970000\n",
            "Iter-28300 loss: 0.2142 validation: 0.970000\n",
            "Iter-28400 loss: 0.2631 validation: 0.970000\n",
            "Iter-28500 loss: 0.2428 validation: 0.970000\n",
            "Iter-28600 loss: 0.1898 validation: 0.970000\n",
            "Iter-28700 loss: 0.1882 validation: 0.970000\n",
            "Iter-28800 loss: 0.2484 validation: 0.970000\n",
            "Iter-28900 loss: 0.1939 validation: 0.970000\n",
            "Iter-29000 loss: 0.2361 validation: 0.970000\n",
            "Iter-29100 loss: 0.2650 validation: 0.970000\n",
            "Iter-29200 loss: 0.1829 validation: 0.970000\n",
            "Iter-29300 loss: 0.1576 validation: 0.970000\n",
            "Iter-29400 loss: 0.1960 validation: 0.970000\n",
            "Iter-29500 loss: 0.1665 validation: 0.970000\n",
            "Iter-29600 loss: 0.2228 validation: 0.970000\n",
            "Iter-29700 loss: 0.2672 validation: 0.970000\n",
            "Iter-29800 loss: 0.2050 validation: 0.970000\n",
            "Iter-29900 loss: 0.1949 validation: 0.970000\n",
            "Iter-30000 loss: 0.1762 validation: 0.970000\n",
            "Iter-30100 loss: 0.1646 validation: 0.970000\n",
            "Iter-30200 loss: 0.2024 validation: 0.970000\n",
            "Iter-30300 loss: 0.1614 validation: 0.970000\n",
            "Iter-30400 loss: 0.2179 validation: 0.970000\n",
            "Iter-30500 loss: 0.2107 validation: 0.970000\n",
            "Iter-30600 loss: 0.2205 validation: 0.980000\n",
            "Iter-30700 loss: 0.1858 validation: 0.970000\n",
            "Iter-30800 loss: 0.1783 validation: 0.970000\n",
            "Iter-30900 loss: 0.1632 validation: 0.980000\n",
            "Iter-31000 loss: 0.1768 validation: 0.970000\n",
            "Iter-31100 loss: 0.1835 validation: 0.980000\n",
            "Iter-31200 loss: 0.2306 validation: 0.970000\n",
            "Iter-31300 loss: 0.1751 validation: 0.980000\n",
            "Iter-31400 loss: 0.1814 validation: 0.970000\n",
            "Iter-31500 loss: 0.2311 validation: 0.980000\n",
            "Iter-31600 loss: 0.1700 validation: 0.980000\n",
            "Iter-31700 loss: 0.2695 validation: 0.980000\n",
            "Iter-31800 loss: 0.1751 validation: 0.970000\n",
            "Iter-31900 loss: 0.1879 validation: 0.980000\n",
            "Iter-32000 loss: 0.2808 validation: 0.980000\n",
            "Iter-32100 loss: 0.1821 validation: 0.980000\n",
            "Iter-32200 loss: 0.2165 validation: 0.980000\n",
            "Iter-32300 loss: 0.2964 validation: 0.980000\n",
            "Iter-32400 loss: 0.2097 validation: 0.980000\n",
            "Iter-32500 loss: 0.1909 validation: 0.970000\n",
            "Iter-32600 loss: 0.2054 validation: 0.970000\n",
            "Iter-32700 loss: 0.2236 validation: 0.970000\n",
            "Iter-32800 loss: 0.1380 validation: 0.970000\n",
            "Iter-32900 loss: 0.2014 validation: 0.970000\n",
            "Iter-33000 loss: 0.1952 validation: 0.970000\n",
            "Iter-33100 loss: 0.1876 validation: 0.980000\n",
            "Iter-33200 loss: 0.2018 validation: 0.970000\n",
            "Iter-33300 loss: 0.2154 validation: 0.970000\n",
            "Iter-33400 loss: 0.2523 validation: 0.970000\n",
            "Iter-33500 loss: 0.3188 validation: 0.970000\n",
            "Iter-33600 loss: 0.2036 validation: 0.980000\n",
            "Iter-33700 loss: 0.1524 validation: 0.970000\n",
            "Iter-33800 loss: 0.2114 validation: 0.970000\n",
            "Iter-33900 loss: 0.1953 validation: 0.970000\n",
            "Iter-34000 loss: 0.1950 validation: 0.970000\n",
            "Iter-34100 loss: 0.1997 validation: 0.970000\n",
            "Iter-34200 loss: 0.2336 validation: 0.970000\n",
            "Iter-34300 loss: 0.2102 validation: 0.970000\n",
            "Iter-34400 loss: 0.2725 validation: 0.970000\n",
            "Iter-34500 loss: 0.1971 validation: 0.970000\n",
            "Iter-34600 loss: 0.1831 validation: 0.980000\n",
            "Iter-34700 loss: 0.1412 validation: 0.970000\n",
            "Iter-34800 loss: 0.1834 validation: 0.970000\n",
            "Iter-34900 loss: 0.2662 validation: 0.970000\n",
            "Iter-35000 loss: 0.1643 validation: 0.980000\n",
            "Iter-35100 loss: 0.2156 validation: 0.970000\n",
            "Iter-35200 loss: 0.2031 validation: 0.970000\n",
            "Iter-35300 loss: 0.1569 validation: 0.980000\n",
            "Iter-35400 loss: 0.2922 validation: 0.980000\n",
            "Iter-35500 loss: 0.1753 validation: 0.980000\n",
            "Iter-35600 loss: 0.2376 validation: 0.970000\n",
            "Iter-35700 loss: 0.1562 validation: 0.980000\n",
            "Iter-35800 loss: 0.2023 validation: 0.970000\n",
            "Iter-35900 loss: 0.1917 validation: 0.980000\n",
            "Iter-36000 loss: 0.1757 validation: 0.980000\n",
            "Iter-36100 loss: 0.2000 validation: 0.980000\n",
            "Iter-36200 loss: 0.2645 validation: 0.970000\n",
            "Iter-36300 loss: 0.1867 validation: 0.980000\n",
            "Iter-36400 loss: 0.2201 validation: 0.980000\n",
            "Iter-36500 loss: 0.2358 validation: 0.980000\n",
            "Iter-36600 loss: 0.1643 validation: 0.980000\n",
            "Iter-36700 loss: 0.2185 validation: 0.970000\n",
            "Iter-36800 loss: 0.2254 validation: 0.970000\n",
            "Iter-36900 loss: 0.2232 validation: 0.970000\n",
            "Iter-37000 loss: 0.1488 validation: 0.970000\n",
            "Iter-37100 loss: 0.1815 validation: 0.970000\n",
            "Iter-37200 loss: 0.2272 validation: 0.970000\n",
            "Iter-37300 loss: 0.2269 validation: 0.980000\n",
            "Iter-37400 loss: 0.1417 validation: 0.970000\n",
            "Iter-37500 loss: 0.1981 validation: 0.970000\n",
            "Iter-37600 loss: 0.1395 validation: 0.970000\n",
            "Iter-37700 loss: 0.1838 validation: 0.980000\n",
            "Iter-37800 loss: 0.1833 validation: 0.970000\n",
            "Iter-37900 loss: 0.1750 validation: 0.970000\n",
            "Iter-38000 loss: 0.2412 validation: 0.980000\n",
            "Iter-38100 loss: 0.2723 validation: 0.980000\n",
            "Iter-38200 loss: 0.1778 validation: 0.980000\n",
            "Iter-38300 loss: 0.2003 validation: 0.970000\n",
            "Iter-38400 loss: 0.1781 validation: 0.980000\n",
            "Iter-38500 loss: 0.1977 validation: 0.980000\n",
            "Iter-38600 loss: 0.1728 validation: 0.970000\n",
            "Iter-38700 loss: 0.1668 validation: 0.970000\n",
            "Iter-38800 loss: 0.2594 validation: 0.980000\n",
            "Iter-38900 loss: 0.1737 validation: 0.970000\n",
            "Iter-39000 loss: 0.1971 validation: 0.970000\n",
            "Iter-39100 loss: 0.2407 validation: 0.970000\n",
            "Iter-39200 loss: 0.2005 validation: 0.970000\n",
            "Iter-39300 loss: 0.1622 validation: 0.980000\n",
            "Iter-39400 loss: 0.1585 validation: 0.970000\n",
            "Iter-39500 loss: 0.1866 validation: 0.980000\n",
            "Iter-39600 loss: 0.1585 validation: 0.970000\n",
            "Iter-39700 loss: 0.1941 validation: 0.980000\n",
            "Iter-39800 loss: 0.1681 validation: 0.970000\n",
            "Iter-39900 loss: 0.2164 validation: 0.980000\n",
            "Iter-40000 loss: 0.1750 validation: 0.980000\n",
            "Iter-40100 loss: 0.1482 validation: 0.970000\n",
            "Iter-40200 loss: 0.1210 validation: 0.980000\n",
            "Iter-40300 loss: 0.1761 validation: 0.970000\n",
            "Iter-40400 loss: 0.2239 validation: 0.980000\n",
            "Iter-40500 loss: 0.2352 validation: 0.980000\n",
            "Iter-40600 loss: 0.1752 validation: 0.980000\n",
            "Iter-40700 loss: 0.1998 validation: 0.980000\n",
            "Iter-40800 loss: 0.1894 validation: 0.980000\n",
            "Iter-40900 loss: 0.2085 validation: 0.980000\n",
            "Iter-41000 loss: 0.1792 validation: 0.970000\n",
            "Iter-41100 loss: 0.1979 validation: 0.970000\n",
            "Iter-41200 loss: 0.2465 validation: 0.980000\n",
            "Iter-41300 loss: 0.1764 validation: 0.970000\n",
            "Iter-41400 loss: 0.1695 validation: 0.980000\n",
            "Iter-41500 loss: 0.1752 validation: 0.970000\n",
            "Iter-41600 loss: 0.1504 validation: 0.970000\n",
            "Iter-41700 loss: 0.1976 validation: 0.970000\n",
            "Iter-41800 loss: 0.1957 validation: 0.970000\n",
            "Iter-41900 loss: 0.1810 validation: 0.970000\n",
            "Iter-42000 loss: 0.2395 validation: 0.980000\n",
            "Iter-42100 loss: 0.2658 validation: 0.970000\n",
            "Iter-42200 loss: 0.2089 validation: 0.970000\n",
            "Iter-42300 loss: 0.1609 validation: 0.970000\n",
            "Iter-42400 loss: 0.1922 validation: 0.970000\n",
            "Iter-42500 loss: 0.1683 validation: 0.970000\n",
            "Iter-42600 loss: 0.1442 validation: 0.970000\n",
            "Iter-42700 loss: 0.1951 validation: 0.970000\n",
            "Iter-42800 loss: 0.1806 validation: 0.980000\n",
            "Iter-42900 loss: 0.1489 validation: 0.980000\n",
            "Iter-43000 loss: 0.1636 validation: 0.970000\n",
            "Iter-43100 loss: 0.1699 validation: 0.970000\n",
            "Iter-43200 loss: 0.1409 validation: 0.980000\n",
            "Iter-43300 loss: 0.1543 validation: 0.970000\n",
            "Iter-43400 loss: 0.1878 validation: 0.970000\n",
            "Iter-43500 loss: 0.1515 validation: 0.970000\n",
            "Iter-43600 loss: 0.1477 validation: 0.970000\n",
            "Iter-43700 loss: 0.2211 validation: 0.980000\n",
            "Iter-43800 loss: 0.1971 validation: 0.980000\n",
            "Iter-43900 loss: 0.2124 validation: 0.970000\n",
            "Iter-44000 loss: 0.2044 validation: 0.980000\n",
            "Iter-44100 loss: 0.1762 validation: 0.980000\n",
            "Iter-44200 loss: 0.1857 validation: 0.980000\n",
            "Iter-44300 loss: 0.1998 validation: 0.980000\n",
            "Iter-44400 loss: 0.1797 validation: 0.970000\n",
            "Iter-44500 loss: 0.1975 validation: 0.970000\n",
            "Iter-44600 loss: 0.1255 validation: 0.980000\n",
            "Iter-44700 loss: 0.1867 validation: 0.980000\n",
            "Iter-44800 loss: 0.1810 validation: 0.980000\n",
            "Iter-44900 loss: 0.1914 validation: 0.980000\n",
            "Iter-45000 loss: 0.1793 validation: 0.980000\n",
            "Iter-45100 loss: 0.1580 validation: 0.970000\n",
            "Iter-45200 loss: 0.1685 validation: 0.980000\n",
            "Iter-45300 loss: 0.1844 validation: 0.970000\n",
            "Iter-45400 loss: 0.1846 validation: 0.980000\n",
            "Iter-45500 loss: 0.1815 validation: 0.980000\n",
            "Iter-45600 loss: 0.1686 validation: 0.980000\n",
            "Iter-45700 loss: 0.1551 validation: 0.980000\n",
            "Iter-45800 loss: 0.1716 validation: 0.980000\n",
            "Iter-45900 loss: 0.1251 validation: 0.980000\n",
            "Iter-46000 loss: 0.1585 validation: 0.980000\n",
            "Iter-46100 loss: 0.1557 validation: 0.980000\n",
            "Iter-46200 loss: 0.1493 validation: 0.980000\n",
            "Iter-46300 loss: 0.1558 validation: 0.980000\n",
            "Iter-46400 loss: 0.1800 validation: 0.980000\n",
            "Iter-46500 loss: 0.1591 validation: 0.980000\n",
            "Iter-46600 loss: 0.1435 validation: 0.980000\n",
            "Iter-46700 loss: 0.1882 validation: 0.980000\n",
            "Iter-46800 loss: 0.1769 validation: 0.980000\n",
            "Iter-46900 loss: 0.1563 validation: 0.980000\n",
            "Iter-47000 loss: 0.1890 validation: 0.980000\n",
            "Iter-47100 loss: 0.1712 validation: 0.970000\n",
            "Iter-47200 loss: 0.1747 validation: 0.970000\n",
            "Iter-47300 loss: 0.1459 validation: 0.980000\n",
            "Iter-47400 loss: 0.1726 validation: 0.980000\n",
            "Iter-47500 loss: 0.1707 validation: 0.970000\n",
            "Iter-47600 loss: 0.1659 validation: 0.980000\n",
            "Iter-47700 loss: 0.1926 validation: 0.980000\n",
            "Iter-47800 loss: 0.1583 validation: 0.970000\n",
            "Iter-47900 loss: 0.2010 validation: 0.970000\n",
            "Iter-48000 loss: 0.2040 validation: 0.980000\n",
            "Iter-48100 loss: 0.2142 validation: 0.980000\n",
            "Iter-48200 loss: 0.2453 validation: 0.980000\n",
            "Iter-48300 loss: 0.1444 validation: 0.980000\n",
            "Iter-48400 loss: 0.1640 validation: 0.970000\n",
            "Iter-48500 loss: 0.1390 validation: 0.970000\n",
            "Iter-48600 loss: 0.1580 validation: 0.980000\n",
            "Iter-48700 loss: 0.1461 validation: 0.980000\n",
            "Iter-48800 loss: 0.1759 validation: 0.970000\n",
            "Iter-48900 loss: 0.1753 validation: 0.970000\n",
            "Iter-49000 loss: 0.1469 validation: 0.970000\n",
            "Iter-49100 loss: 0.1295 validation: 0.980000\n",
            "Iter-49200 loss: 0.1496 validation: 0.970000\n",
            "Iter-49300 loss: 0.1682 validation: 0.970000\n",
            "Iter-49400 loss: 0.1632 validation: 0.970000\n",
            "Iter-49500 loss: 0.1536 validation: 0.980000\n",
            "Iter-49600 loss: 0.2290 validation: 0.970000\n",
            "Iter-49700 loss: 0.1621 validation: 0.980000\n",
            "Iter-49800 loss: 0.1868 validation: 0.970000\n",
            "Iter-49900 loss: 0.1978 validation: 0.970000\n",
            "Iter-50000 loss: 0.1490 validation: 0.970000\n",
            "Iter-50100 loss: 0.1702 validation: 0.980000\n",
            "Iter-50200 loss: 0.1553 validation: 0.980000\n",
            "Iter-50300 loss: 0.1639 validation: 0.980000\n",
            "Iter-50400 loss: 0.1920 validation: 0.980000\n",
            "Iter-50500 loss: 0.1754 validation: 0.980000\n",
            "Iter-50600 loss: 0.2027 validation: 0.980000\n",
            "Iter-50700 loss: 0.2068 validation: 0.980000\n",
            "Iter-50800 loss: 0.1353 validation: 0.980000\n",
            "Iter-50900 loss: 0.1649 validation: 0.980000\n",
            "Iter-51000 loss: 0.1578 validation: 0.980000\n",
            "Iter-51100 loss: 0.2083 validation: 0.980000\n",
            "Iter-51200 loss: 0.1474 validation: 0.980000\n",
            "Iter-51300 loss: 0.1706 validation: 0.980000\n",
            "Iter-51400 loss: 0.2150 validation: 0.970000\n",
            "Iter-51500 loss: 0.1430 validation: 0.980000\n",
            "Iter-51600 loss: 0.1838 validation: 0.980000\n",
            "Iter-51700 loss: 0.1886 validation: 0.980000\n",
            "Iter-51800 loss: 0.1694 validation: 0.980000\n",
            "Iter-51900 loss: 0.1540 validation: 0.980000\n",
            "Iter-52000 loss: 0.2152 validation: 0.980000\n",
            "Iter-52100 loss: 0.1556 validation: 0.980000\n",
            "Iter-52200 loss: 0.1829 validation: 0.980000\n",
            "Iter-52300 loss: 0.1580 validation: 0.980000\n",
            "Iter-52400 loss: 0.1393 validation: 0.980000\n",
            "Iter-52500 loss: 0.1260 validation: 0.970000\n",
            "Iter-52600 loss: 0.1809 validation: 0.980000\n",
            "Iter-52700 loss: 0.1648 validation: 0.980000\n",
            "Iter-52800 loss: 0.1118 validation: 0.980000\n",
            "Iter-52900 loss: 0.1408 validation: 0.970000\n",
            "Iter-53000 loss: 0.1675 validation: 0.980000\n",
            "Iter-53100 loss: 0.1921 validation: 0.980000\n",
            "Iter-53200 loss: 0.1833 validation: 0.970000\n",
            "Iter-53300 loss: 0.1507 validation: 0.970000\n",
            "Iter-53400 loss: 0.1304 validation: 0.970000\n",
            "Iter-53500 loss: 0.1746 validation: 0.970000\n",
            "Iter-53600 loss: 0.1649 validation: 0.970000\n",
            "Iter-53700 loss: 0.1994 validation: 0.970000\n",
            "Iter-53800 loss: 0.1425 validation: 0.980000\n",
            "Iter-53900 loss: 0.1767 validation: 0.980000\n",
            "Iter-54000 loss: 0.1667 validation: 0.970000\n",
            "Iter-54100 loss: 0.1905 validation: 0.980000\n",
            "Iter-54200 loss: 0.1474 validation: 0.970000\n",
            "Iter-54300 loss: 0.1906 validation: 0.980000\n",
            "Iter-54400 loss: 0.1600 validation: 0.970000\n",
            "Iter-54500 loss: 0.2258 validation: 0.980000\n",
            "Iter-54600 loss: 0.1228 validation: 0.980000\n",
            "Iter-54700 loss: 0.1799 validation: 0.980000\n",
            "Iter-54800 loss: 0.1437 validation: 0.980000\n",
            "Iter-54900 loss: 0.1441 validation: 0.970000\n",
            "Iter-55000 loss: 0.1900 validation: 0.970000\n",
            "Iter-55100 loss: 0.1636 validation: 0.970000\n",
            "Iter-55200 loss: 0.1464 validation: 0.970000\n",
            "Iter-55300 loss: 0.1673 validation: 0.970000\n",
            "Iter-55400 loss: 0.1739 validation: 0.980000\n",
            "Iter-55500 loss: 0.1186 validation: 0.970000\n",
            "Iter-55600 loss: 0.1799 validation: 0.980000\n",
            "Iter-55700 loss: 0.1726 validation: 0.980000\n",
            "Iter-55800 loss: 0.1842 validation: 0.980000\n",
            "Iter-55900 loss: 0.2005 validation: 0.980000\n",
            "Iter-56000 loss: 0.1871 validation: 0.970000\n",
            "Iter-56100 loss: 0.1703 validation: 0.980000\n",
            "Iter-56200 loss: 0.2106 validation: 0.980000\n",
            "Iter-56300 loss: 0.1872 validation: 0.980000\n",
            "Iter-56400 loss: 0.1504 validation: 0.980000\n",
            "Iter-56500 loss: 0.2017 validation: 0.980000\n",
            "Iter-56600 loss: 0.1784 validation: 0.980000\n",
            "Iter-56700 loss: 0.1596 validation: 0.980000\n",
            "Iter-56800 loss: 0.1300 validation: 0.980000\n",
            "Iter-56900 loss: 0.1908 validation: 0.980000\n",
            "Iter-57000 loss: 0.1485 validation: 0.980000\n",
            "Iter-57100 loss: 0.1247 validation: 0.980000\n",
            "Iter-57200 loss: 0.1442 validation: 0.980000\n",
            "Iter-57300 loss: 0.1414 validation: 0.980000\n",
            "Iter-57400 loss: 0.1334 validation: 0.980000\n",
            "Iter-57500 loss: 0.1681 validation: 0.980000\n",
            "Iter-57600 loss: 0.1376 validation: 0.980000\n",
            "Iter-57700 loss: 0.1426 validation: 0.980000\n",
            "Iter-57800 loss: 0.1727 validation: 0.980000\n",
            "Iter-57900 loss: 0.1600 validation: 0.980000\n",
            "Iter-58000 loss: 0.1170 validation: 0.980000\n",
            "Iter-58100 loss: 0.1340 validation: 0.980000\n",
            "Iter-58200 loss: 0.1350 validation: 0.980000\n",
            "Iter-58300 loss: 0.2156 validation: 0.980000\n",
            "Iter-58400 loss: 0.1314 validation: 0.980000\n",
            "Iter-58500 loss: 0.1510 validation: 0.980000\n",
            "Iter-58600 loss: 0.1642 validation: 0.980000\n",
            "Iter-58700 loss: 0.1241 validation: 0.980000\n",
            "Iter-58800 loss: 0.1456 validation: 0.980000\n",
            "Iter-58900 loss: 0.1609 validation: 0.980000\n",
            "Iter-59000 loss: 0.1226 validation: 0.980000\n",
            "Iter-59100 loss: 0.1791 validation: 0.980000\n",
            "Iter-59200 loss: 0.1748 validation: 0.980000\n",
            "Iter-59300 loss: 0.1682 validation: 0.980000\n",
            "Iter-59400 loss: 0.1279 validation: 0.980000\n",
            "Iter-59500 loss: 0.1347 validation: 0.980000\n",
            "Iter-59600 loss: 0.1507 validation: 0.980000\n",
            "Iter-59700 loss: 0.1552 validation: 0.980000\n",
            "Iter-59800 loss: 0.1628 validation: 0.980000\n",
            "Iter-59900 loss: 0.1276 validation: 0.980000\n",
            "Iter-60000 loss: 0.1417 validation: 0.980000\n",
            "Iter-60100 loss: 0.1804 validation: 0.980000\n",
            "Iter-60200 loss: 0.1643 validation: 0.980000\n",
            "Iter-60300 loss: 0.1503 validation: 0.980000\n",
            "Iter-60400 loss: 0.1019 validation: 0.980000\n",
            "Iter-60500 loss: 0.1385 validation: 0.980000\n",
            "Iter-60600 loss: 0.1679 validation: 0.980000\n",
            "Iter-60700 loss: 0.1251 validation: 0.980000\n",
            "Iter-60800 loss: 0.1455 validation: 0.980000\n",
            "Iter-60900 loss: 0.1774 validation: 0.980000\n",
            "Iter-61000 loss: 0.1448 validation: 0.980000\n",
            "Iter-61100 loss: 0.1092 validation: 0.980000\n",
            "Iter-61200 loss: 0.2054 validation: 0.970000\n",
            "Iter-61300 loss: 0.1540 validation: 0.980000\n",
            "Iter-61400 loss: 0.1427 validation: 0.980000\n",
            "Iter-61500 loss: 0.1026 validation: 0.980000\n",
            "Iter-61600 loss: 0.1387 validation: 0.980000\n",
            "Iter-61700 loss: 0.2048 validation: 0.980000\n",
            "Iter-61800 loss: 0.1353 validation: 0.980000\n",
            "Iter-61900 loss: 0.1236 validation: 0.980000\n",
            "Iter-62000 loss: 0.1734 validation: 0.980000\n",
            "Iter-62100 loss: 0.1491 validation: 0.980000\n",
            "Iter-62200 loss: 0.1580 validation: 0.980000\n",
            "Iter-62300 loss: 0.1459 validation: 0.980000\n",
            "Iter-62400 loss: 0.1685 validation: 0.980000\n",
            "Iter-62500 loss: 0.2098 validation: 0.980000\n",
            "Iter-62600 loss: 0.1656 validation: 0.980000\n",
            "Iter-62700 loss: 0.1558 validation: 0.980000\n",
            "Iter-62800 loss: 0.1437 validation: 0.980000\n",
            "Iter-62900 loss: 0.1630 validation: 0.980000\n",
            "Iter-63000 loss: 0.1236 validation: 0.980000\n",
            "Iter-63100 loss: 0.1674 validation: 0.980000\n",
            "Iter-63200 loss: 0.1619 validation: 0.980000\n",
            "Iter-63300 loss: 0.1358 validation: 0.980000\n",
            "Iter-63400 loss: 0.1346 validation: 0.980000\n",
            "Iter-63500 loss: 0.2218 validation: 0.980000\n",
            "Iter-63600 loss: 0.1507 validation: 0.980000\n",
            "Iter-63700 loss: 0.1426 validation: 0.980000\n",
            "Iter-63800 loss: 0.1505 validation: 0.980000\n",
            "Iter-63900 loss: 0.1300 validation: 0.980000\n",
            "Iter-64000 loss: 0.1514 validation: 0.980000\n",
            "Iter-64100 loss: 0.2212 validation: 0.980000\n",
            "Iter-64200 loss: 0.1646 validation: 0.980000\n",
            "Iter-64300 loss: 0.1455 validation: 0.980000\n",
            "Iter-64400 loss: 0.1958 validation: 0.980000\n",
            "Iter-64500 loss: 0.1611 validation: 0.980000\n",
            "Iter-64600 loss: 0.1497 validation: 0.980000\n",
            "Iter-64700 loss: 0.1638 validation: 0.980000\n",
            "Iter-64800 loss: 0.1790 validation: 0.980000\n",
            "Iter-64900 loss: 0.1213 validation: 0.980000\n",
            "Iter-65000 loss: 0.1509 validation: 0.980000\n",
            "Iter-65100 loss: 0.1477 validation: 0.980000\n",
            "Iter-65200 loss: 0.1289 validation: 0.980000\n",
            "Iter-65300 loss: 0.1659 validation: 0.980000\n",
            "Iter-65400 loss: 0.2233 validation: 0.980000\n",
            "Iter-65500 loss: 0.1219 validation: 0.980000\n",
            "Iter-65600 loss: 0.1246 validation: 0.980000\n",
            "Iter-65700 loss: 0.1408 validation: 0.980000\n",
            "Iter-65800 loss: 0.1272 validation: 0.980000\n",
            "Iter-65900 loss: 0.1540 validation: 0.980000\n",
            "Iter-66000 loss: 0.1273 validation: 0.980000\n",
            "Iter-66100 loss: 0.1392 validation: 0.980000\n",
            "Iter-66200 loss: 0.1368 validation: 0.980000\n",
            "Iter-66300 loss: 0.1501 validation: 0.980000\n",
            "Iter-66400 loss: 0.1111 validation: 0.980000\n",
            "Iter-66500 loss: 0.2255 validation: 0.980000\n",
            "Iter-66600 loss: 0.1489 validation: 0.980000\n",
            "Iter-66700 loss: 0.1242 validation: 0.980000\n",
            "Iter-66800 loss: 0.1440 validation: 0.980000\n",
            "Iter-66900 loss: 0.1449 validation: 0.980000\n",
            "Iter-67000 loss: 0.1470 validation: 0.980000\n",
            "Iter-67100 loss: 0.1382 validation: 0.980000\n",
            "Iter-67200 loss: 0.1231 validation: 0.980000\n",
            "Iter-67300 loss: 0.1683 validation: 0.980000\n",
            "Iter-67400 loss: 0.1398 validation: 0.980000\n",
            "Iter-67500 loss: 0.1296 validation: 0.980000\n",
            "Iter-67600 loss: 0.1657 validation: 0.980000\n",
            "Iter-67700 loss: 0.1382 validation: 0.980000\n",
            "Iter-67800 loss: 0.1340 validation: 0.980000\n",
            "Iter-67900 loss: 0.1655 validation: 0.980000\n",
            "Iter-68000 loss: 0.2210 validation: 0.980000\n",
            "Iter-68100 loss: 0.1512 validation: 0.980000\n",
            "Iter-68200 loss: 0.1815 validation: 0.980000\n",
            "Iter-68300 loss: 0.1405 validation: 0.980000\n",
            "Iter-68400 loss: 0.1362 validation: 0.980000\n",
            "Iter-68500 loss: 0.1348 validation: 0.980000\n",
            "Iter-68600 loss: 0.1288 validation: 0.980000\n",
            "Iter-68700 loss: 0.1584 validation: 0.980000\n",
            "Iter-68800 loss: 0.1627 validation: 0.980000\n",
            "Iter-68900 loss: 0.1240 validation: 0.980000\n",
            "Iter-69000 loss: 0.1792 validation: 0.980000\n",
            "Iter-69100 loss: 0.1344 validation: 0.980000\n",
            "Iter-69200 loss: 0.1260 validation: 0.980000\n",
            "Iter-69300 loss: 0.1316 validation: 0.980000\n",
            "Iter-69400 loss: 0.1687 validation: 0.980000\n",
            "Iter-69500 loss: 0.1168 validation: 0.980000\n",
            "Iter-69600 loss: 0.1552 validation: 0.970000\n",
            "Iter-69700 loss: 0.1002 validation: 0.980000\n",
            "Iter-69800 loss: 0.1280 validation: 0.980000\n",
            "Iter-69900 loss: 0.1222 validation: 0.980000\n",
            "Iter-70000 loss: 0.1232 validation: 0.980000\n",
            "Iter-70100 loss: 0.1964 validation: 0.970000\n",
            "Iter-70200 loss: 0.1328 validation: 0.980000\n",
            "Iter-70300 loss: 0.1378 validation: 0.980000\n",
            "Iter-70400 loss: 0.1499 validation: 0.980000\n",
            "Iter-70500 loss: 0.1341 validation: 0.980000\n",
            "Iter-70600 loss: 0.1090 validation: 0.970000\n",
            "Iter-70700 loss: 0.1851 validation: 0.980000\n",
            "Iter-70800 loss: 0.1500 validation: 0.970000\n",
            "Iter-70900 loss: 0.1327 validation: 0.980000\n",
            "Iter-71000 loss: 0.1735 validation: 0.980000\n",
            "Iter-71100 loss: 0.1386 validation: 0.980000\n",
            "Iter-71200 loss: 0.1445 validation: 0.980000\n",
            "Iter-71300 loss: 0.1342 validation: 0.980000\n",
            "Iter-71400 loss: 0.1539 validation: 0.980000\n",
            "Iter-71500 loss: 0.1383 validation: 0.980000\n",
            "Iter-71600 loss: 0.1199 validation: 0.980000\n",
            "Iter-71700 loss: 0.1392 validation: 0.980000\n",
            "Iter-71800 loss: 0.1383 validation: 0.980000\n",
            "Iter-71900 loss: 0.1351 validation: 0.980000\n",
            "Iter-72000 loss: 0.1414 validation: 0.980000\n",
            "Iter-72100 loss: 0.1090 validation: 0.980000\n",
            "Iter-72200 loss: 0.1582 validation: 0.980000\n",
            "Iter-72300 loss: 0.1356 validation: 0.980000\n",
            "Iter-72400 loss: 0.1360 validation: 0.980000\n",
            "Iter-72500 loss: 0.1228 validation: 0.980000\n",
            "Iter-72600 loss: 0.1337 validation: 0.980000\n",
            "Iter-72700 loss: 0.1393 validation: 0.980000\n",
            "Iter-72800 loss: 0.1504 validation: 0.980000\n",
            "Iter-72900 loss: 0.1333 validation: 0.980000\n",
            "Iter-73000 loss: 0.1124 validation: 0.980000\n",
            "Iter-73100 loss: 0.1540 validation: 0.980000\n",
            "Iter-73200 loss: 0.1321 validation: 0.970000\n",
            "Iter-73300 loss: 0.1219 validation: 0.980000\n",
            "Iter-73400 loss: 0.1657 validation: 0.980000\n",
            "Iter-73500 loss: 0.1202 validation: 0.980000\n",
            "Iter-73600 loss: 0.1248 validation: 0.980000\n",
            "Iter-73700 loss: 0.1017 validation: 0.980000\n",
            "Iter-73800 loss: 0.1336 validation: 0.980000\n",
            "Iter-73900 loss: 0.1112 validation: 0.980000\n",
            "Iter-74000 loss: 0.1288 validation: 0.980000\n",
            "Iter-74100 loss: 0.1402 validation: 0.980000\n",
            "Iter-74200 loss: 0.1274 validation: 0.970000\n",
            "Iter-74300 loss: 0.1252 validation: 0.980000\n",
            "Iter-74400 loss: 0.1230 validation: 0.970000\n",
            "Iter-74500 loss: 0.1618 validation: 0.970000\n",
            "Iter-74600 loss: 0.1862 validation: 0.980000\n",
            "Iter-74700 loss: 0.1326 validation: 0.980000\n",
            "Iter-74800 loss: 0.1484 validation: 0.980000\n",
            "Iter-74900 loss: 0.1155 validation: 0.980000\n",
            "Iter-75000 loss: 0.1384 validation: 0.980000\n",
            "Iter-75100 loss: 0.1433 validation: 0.980000\n",
            "Iter-75200 loss: 0.1355 validation: 0.980000\n",
            "Iter-75300 loss: 0.1291 validation: 0.980000\n",
            "Iter-75400 loss: 0.1234 validation: 0.980000\n",
            "Iter-75500 loss: 0.1273 validation: 0.980000\n",
            "Iter-75600 loss: 0.1025 validation: 0.980000\n",
            "Iter-75700 loss: 0.1253 validation: 0.980000\n",
            "Iter-75800 loss: 0.1301 validation: 0.980000\n",
            "Iter-75900 loss: 0.1721 validation: 0.980000\n",
            "Iter-76000 loss: 0.1388 validation: 0.980000\n",
            "Iter-76100 loss: 0.1264 validation: 0.980000\n",
            "Iter-76200 loss: 0.1552 validation: 0.980000\n",
            "Iter-76300 loss: 0.1148 validation: 0.980000\n",
            "Iter-76400 loss: 0.1653 validation: 0.980000\n",
            "Iter-76500 loss: 0.1336 validation: 0.970000\n",
            "Iter-76600 loss: 0.1884 validation: 0.970000\n",
            "Iter-76700 loss: 0.1267 validation: 0.970000\n",
            "Iter-76800 loss: 0.1088 validation: 0.980000\n",
            "Iter-76900 loss: 0.1458 validation: 0.980000\n",
            "Iter-77000 loss: 0.1505 validation: 0.980000\n",
            "Iter-77100 loss: 0.0983 validation: 0.970000\n",
            "Iter-77200 loss: 0.1274 validation: 0.970000\n",
            "Iter-77300 loss: 0.1458 validation: 0.980000\n",
            "Iter-77400 loss: 0.1257 validation: 0.980000\n",
            "Iter-77500 loss: 0.1352 validation: 0.970000\n",
            "Iter-77600 loss: 0.1164 validation: 0.980000\n",
            "Iter-77700 loss: 0.1246 validation: 0.980000\n",
            "Iter-77800 loss: 0.1326 validation: 0.980000\n",
            "Iter-77900 loss: 0.1317 validation: 0.980000\n",
            "Iter-78000 loss: 0.1543 validation: 0.980000\n",
            "Iter-78100 loss: 0.1480 validation: 0.980000\n",
            "Iter-78200 loss: 0.1149 validation: 0.980000\n",
            "Iter-78300 loss: 0.1573 validation: 0.980000\n",
            "Iter-78400 loss: 0.1241 validation: 0.980000\n",
            "Iter-78500 loss: 0.1422 validation: 0.980000\n",
            "Iter-78600 loss: 0.1546 validation: 0.980000\n",
            "Iter-78700 loss: 0.1092 validation: 0.980000\n",
            "Iter-78800 loss: 0.1502 validation: 0.980000\n",
            "Iter-78900 loss: 0.1332 validation: 0.970000\n",
            "Iter-79000 loss: 0.1817 validation: 0.980000\n",
            "Iter-79100 loss: 0.1591 validation: 0.980000\n",
            "Iter-79200 loss: 0.1383 validation: 0.980000\n",
            "Iter-79300 loss: 0.1101 validation: 0.980000\n",
            "Iter-79400 loss: 0.1300 validation: 0.980000\n",
            "Iter-79500 loss: 0.1097 validation: 0.980000\n",
            "Iter-79600 loss: 0.0988 validation: 0.980000\n",
            "Iter-79700 loss: 0.1430 validation: 0.980000\n",
            "Iter-79800 loss: 0.1476 validation: 0.980000\n",
            "Iter-79900 loss: 0.1413 validation: 0.980000\n",
            "Iter-80000 loss: 0.1382 validation: 0.980000\n",
            "Iter-80100 loss: 0.1335 validation: 0.980000\n",
            "Iter-80200 loss: 0.1871 validation: 0.980000\n",
            "Iter-80300 loss: 0.1355 validation: 0.980000\n",
            "Iter-80400 loss: 0.0925 validation: 0.980000\n",
            "Iter-80500 loss: 0.1217 validation: 0.980000\n",
            "Iter-80600 loss: 0.1458 validation: 0.980000\n",
            "Iter-80700 loss: 0.1137 validation: 0.980000\n",
            "Iter-80800 loss: 0.1230 validation: 0.980000\n",
            "Iter-80900 loss: 0.1386 validation: 0.980000\n",
            "Iter-81000 loss: 0.1314 validation: 0.980000\n",
            "Iter-81100 loss: 0.1106 validation: 0.980000\n",
            "Iter-81200 loss: 0.1616 validation: 0.980000\n",
            "Iter-81300 loss: 0.1252 validation: 0.980000\n",
            "Iter-81400 loss: 0.1217 validation: 0.980000\n",
            "Iter-81500 loss: 0.1251 validation: 0.980000\n",
            "Iter-81600 loss: 0.1358 validation: 0.980000\n",
            "Iter-81700 loss: 0.1300 validation: 0.980000\n",
            "Iter-81800 loss: 0.1562 validation: 0.980000\n",
            "Iter-81900 loss: 0.1565 validation: 0.980000\n",
            "Iter-82000 loss: 0.1374 validation: 0.980000\n",
            "Iter-82100 loss: 0.1454 validation: 0.980000\n",
            "Iter-82200 loss: 0.1350 validation: 0.980000\n",
            "Iter-82300 loss: 0.1176 validation: 0.980000\n",
            "Iter-82400 loss: 0.0950 validation: 0.980000\n",
            "Iter-82500 loss: 0.2088 validation: 0.980000\n",
            "Iter-82600 loss: 0.1649 validation: 0.980000\n",
            "Iter-82700 loss: 0.1229 validation: 0.980000\n",
            "Iter-82800 loss: 0.1361 validation: 0.980000\n",
            "Iter-82900 loss: 0.1317 validation: 0.980000\n",
            "Iter-83000 loss: 0.1320 validation: 0.980000\n",
            "Iter-83100 loss: 0.1344 validation: 0.980000\n",
            "Iter-83200 loss: 0.1384 validation: 0.980000\n",
            "Iter-83300 loss: 0.1382 validation: 0.980000\n",
            "Iter-83400 loss: 0.1407 validation: 0.980000\n",
            "Iter-83500 loss: 0.1593 validation: 0.980000\n",
            "Iter-83600 loss: 0.1361 validation: 0.980000\n",
            "Iter-83700 loss: 0.1192 validation: 0.980000\n",
            "Iter-83800 loss: 0.1231 validation: 0.980000\n",
            "Iter-83900 loss: 0.1532 validation: 0.980000\n",
            "Iter-84000 loss: 0.1041 validation: 0.980000\n",
            "Iter-84100 loss: 0.1231 validation: 0.980000\n",
            "Iter-84200 loss: 0.0946 validation: 0.980000\n",
            "Iter-84300 loss: 0.1056 validation: 0.980000\n",
            "Iter-84400 loss: 0.1446 validation: 0.980000\n",
            "Iter-84500 loss: 0.1055 validation: 0.980000\n",
            "Iter-84600 loss: 0.1400 validation: 0.970000\n",
            "Iter-84700 loss: 0.1345 validation: 0.980000\n",
            "Iter-84800 loss: 0.1310 validation: 0.980000\n",
            "Iter-84900 loss: 0.1201 validation: 0.980000\n",
            "Iter-85000 loss: 0.1804 validation: 0.980000\n",
            "Iter-85100 loss: 0.1407 validation: 0.980000\n",
            "Iter-85200 loss: 0.1236 validation: 0.980000\n",
            "Iter-85300 loss: 0.1032 validation: 0.980000\n",
            "Iter-85400 loss: 0.1699 validation: 0.980000\n",
            "Iter-85500 loss: 0.1294 validation: 0.980000\n",
            "Iter-85600 loss: 0.1548 validation: 0.980000\n",
            "Iter-85700 loss: 0.1245 validation: 0.980000\n",
            "Iter-85800 loss: 0.1027 validation: 0.980000\n",
            "Iter-85900 loss: 0.1169 validation: 0.980000\n",
            "Iter-86000 loss: 0.1327 validation: 0.980000\n",
            "Iter-86100 loss: 0.1641 validation: 0.980000\n",
            "Iter-86200 loss: 0.1055 validation: 0.980000\n",
            "Iter-86300 loss: 0.1189 validation: 0.980000\n",
            "Iter-86400 loss: 0.1258 validation: 0.980000\n",
            "Iter-86500 loss: 0.1336 validation: 0.980000\n",
            "Iter-86600 loss: 0.1056 validation: 0.980000\n",
            "Iter-86700 loss: 0.1028 validation: 0.980000\n",
            "Iter-86800 loss: 0.1380 validation: 0.980000\n",
            "Iter-86900 loss: 0.1014 validation: 0.980000\n",
            "Iter-87000 loss: 0.1247 validation: 0.980000\n",
            "Iter-87100 loss: 0.1330 validation: 0.980000\n",
            "Iter-87200 loss: 0.1161 validation: 0.980000\n",
            "Iter-87300 loss: 0.1104 validation: 0.980000\n",
            "Iter-87400 loss: 0.1635 validation: 0.980000\n",
            "Iter-87500 loss: 0.1100 validation: 0.980000\n",
            "Iter-87600 loss: 0.1199 validation: 0.980000\n",
            "Iter-87700 loss: 0.1613 validation: 0.980000\n",
            "Iter-87800 loss: 0.1315 validation: 0.970000\n",
            "Iter-87900 loss: 0.1195 validation: 0.970000\n",
            "Iter-88000 loss: 0.1215 validation: 0.980000\n",
            "Iter-88100 loss: 0.1252 validation: 0.980000\n",
            "Iter-88200 loss: 0.1346 validation: 0.980000\n",
            "Iter-88300 loss: 0.1336 validation: 0.980000\n",
            "Iter-88400 loss: 0.1529 validation: 0.980000\n",
            "Iter-88500 loss: 0.1124 validation: 0.980000\n",
            "Iter-88600 loss: 0.1364 validation: 0.980000\n",
            "Iter-88700 loss: 0.1413 validation: 0.970000\n",
            "Iter-88800 loss: 0.1381 validation: 0.970000\n",
            "Iter-88900 loss: 0.0964 validation: 0.980000\n",
            "Iter-89000 loss: 0.1549 validation: 0.980000\n",
            "Iter-89100 loss: 0.1221 validation: 0.980000\n",
            "Iter-89200 loss: 0.1486 validation: 0.980000\n",
            "Iter-89300 loss: 0.1122 validation: 0.980000\n",
            "Iter-89400 loss: 0.1475 validation: 0.980000\n",
            "Iter-89500 loss: 0.1451 validation: 0.980000\n",
            "Iter-89600 loss: 0.1134 validation: 0.980000\n",
            "Iter-89700 loss: 0.1280 validation: 0.980000\n",
            "Iter-89800 loss: 0.1666 validation: 0.980000\n",
            "Iter-89900 loss: 0.1393 validation: 0.980000\n",
            "Iter-90000 loss: 0.1204 validation: 0.980000\n",
            "Iter-90100 loss: 0.1448 validation: 0.980000\n",
            "Iter-90200 loss: 0.1330 validation: 0.980000\n",
            "Iter-90300 loss: 0.1444 validation: 0.980000\n",
            "Iter-90400 loss: 0.1327 validation: 0.980000\n",
            "Iter-90500 loss: 0.1482 validation: 0.980000\n",
            "Iter-90600 loss: 0.1443 validation: 0.980000\n",
            "Iter-90700 loss: 0.1159 validation: 0.980000\n",
            "Iter-90800 loss: 0.1001 validation: 0.980000\n",
            "Iter-90900 loss: 0.1126 validation: 0.980000\n",
            "Iter-91000 loss: 0.1295 validation: 0.980000\n",
            "Iter-91100 loss: 0.1211 validation: 0.980000\n",
            "Iter-91200 loss: 0.1360 validation: 0.980000\n",
            "Iter-91300 loss: 0.1290 validation: 0.980000\n",
            "Iter-91400 loss: 0.1477 validation: 0.980000\n",
            "Iter-91500 loss: 0.1426 validation: 0.970000\n",
            "Iter-91600 loss: 0.1212 validation: 0.980000\n",
            "Iter-91700 loss: 0.1111 validation: 0.980000\n",
            "Iter-91800 loss: 0.1295 validation: 0.980000\n",
            "Iter-91900 loss: 0.1386 validation: 0.980000\n",
            "Iter-92000 loss: 0.1377 validation: 0.980000\n",
            "Iter-92100 loss: 0.1203 validation: 0.980000\n",
            "Iter-92200 loss: 0.1228 validation: 0.980000\n",
            "Iter-92300 loss: 0.1303 validation: 0.980000\n",
            "Iter-92400 loss: 0.1005 validation: 0.980000\n",
            "Iter-92500 loss: 0.1188 validation: 0.980000\n",
            "Iter-92600 loss: 0.1017 validation: 0.980000\n",
            "Iter-92700 loss: 0.1420 validation: 0.970000\n",
            "Iter-92800 loss: 0.1290 validation: 0.980000\n",
            "Iter-92900 loss: 0.1591 validation: 0.980000\n",
            "Iter-93000 loss: 0.1081 validation: 0.980000\n",
            "Iter-93100 loss: 0.1067 validation: 0.980000\n",
            "Iter-93200 loss: 0.1100 validation: 0.980000\n",
            "Iter-93300 loss: 0.1207 validation: 0.980000\n",
            "Iter-93400 loss: 0.1161 validation: 0.980000\n",
            "Iter-93500 loss: 0.1433 validation: 0.980000\n",
            "Iter-93600 loss: 0.1487 validation: 0.980000\n",
            "Iter-93700 loss: 0.1004 validation: 0.980000\n",
            "Iter-93800 loss: 0.1072 validation: 0.980000\n",
            "Iter-93900 loss: 0.1144 validation: 0.980000\n",
            "Iter-94000 loss: 0.1218 validation: 0.980000\n",
            "Iter-94100 loss: 0.1184 validation: 0.980000\n",
            "Iter-94200 loss: 0.1084 validation: 0.970000\n",
            "Iter-94300 loss: 0.1120 validation: 0.980000\n",
            "Iter-94400 loss: 0.1028 validation: 0.980000\n",
            "Iter-94500 loss: 0.1192 validation: 0.980000\n",
            "Iter-94600 loss: 0.1147 validation: 0.980000\n",
            "Iter-94700 loss: 0.1048 validation: 0.980000\n",
            "Iter-94800 loss: 0.1390 validation: 0.980000\n",
            "Iter-94900 loss: 0.1404 validation: 0.980000\n",
            "Iter-95000 loss: 0.1056 validation: 0.970000\n",
            "Iter-95100 loss: 0.1092 validation: 0.980000\n",
            "Iter-95200 loss: 0.1154 validation: 0.980000\n",
            "Iter-95300 loss: 0.1211 validation: 0.980000\n",
            "Iter-95400 loss: 0.1363 validation: 0.980000\n",
            "Iter-95500 loss: 0.1311 validation: 0.980000\n",
            "Iter-95600 loss: 0.1307 validation: 0.980000\n",
            "Iter-95700 loss: 0.1458 validation: 0.980000\n",
            "Iter-95800 loss: 0.1249 validation: 0.980000\n",
            "Iter-95900 loss: 0.1139 validation: 0.980000\n",
            "Iter-96000 loss: 0.1505 validation: 0.970000\n",
            "Iter-96100 loss: 0.1070 validation: 0.970000\n",
            "Iter-96200 loss: 0.1273 validation: 0.970000\n",
            "Iter-96300 loss: 0.1133 validation: 0.980000\n",
            "Iter-96400 loss: 0.1327 validation: 0.980000\n",
            "Iter-96500 loss: 0.1292 validation: 0.980000\n",
            "Iter-96600 loss: 0.1131 validation: 0.980000\n",
            "Iter-96700 loss: 0.1171 validation: 0.980000\n",
            "Iter-96800 loss: 0.1388 validation: 0.980000\n",
            "Iter-96900 loss: 0.1119 validation: 0.970000\n",
            "Iter-97000 loss: 0.1320 validation: 0.980000\n",
            "Iter-97100 loss: 0.1133 validation: 0.980000\n",
            "Iter-97200 loss: 0.0997 validation: 0.980000\n",
            "Iter-97300 loss: 0.1277 validation: 0.980000\n",
            "Iter-97400 loss: 0.1100 validation: 0.980000\n",
            "Iter-97500 loss: 0.0922 validation: 0.980000\n",
            "Iter-97600 loss: 0.1340 validation: 0.980000\n",
            "Iter-97700 loss: 0.1547 validation: 0.970000\n",
            "Iter-97800 loss: 0.1683 validation: 0.980000\n",
            "Iter-97900 loss: 0.1356 validation: 0.980000\n",
            "Iter-98000 loss: 0.1514 validation: 0.980000\n",
            "Iter-98100 loss: 0.1122 validation: 0.980000\n",
            "Iter-98200 loss: 0.1169 validation: 0.980000\n",
            "Iter-98300 loss: 0.1048 validation: 0.980000\n",
            "Iter-98400 loss: 0.1050 validation: 0.980000\n",
            "Iter-98500 loss: 0.1266 validation: 0.980000\n",
            "Iter-98600 loss: 0.1241 validation: 0.980000\n",
            "Iter-98700 loss: 0.1051 validation: 0.980000\n",
            "Iter-98800 loss: 0.1255 validation: 0.980000\n",
            "Iter-98900 loss: 0.1151 validation: 0.980000\n",
            "Iter-99000 loss: 0.1208 validation: 0.980000\n",
            "Iter-99100 loss: 0.1199 validation: 0.980000\n",
            "Iter-99200 loss: 0.1377 validation: 0.980000\n",
            "Iter-99300 loss: 0.1201 validation: 0.980000\n",
            "Iter-99400 loss: 0.1055 validation: 0.980000\n",
            "Iter-99500 loss: 0.1041 validation: 0.980000\n",
            "Iter-99600 loss: 0.1204 validation: 0.980000\n",
            "Iter-99700 loss: 0.1241 validation: 0.980000\n",
            "Iter-99800 loss: 0.1369 validation: 0.980000\n",
            "Iter-99900 loss: 0.1338 validation: 0.970000\n",
            "Iter-100000 loss: 0.0989 validation: 0.980000\n",
            "\n",
            "Best max_norm:  4.0 best dropout rate for input:  0.85 best dropout rate for hidden layers:  0.5 and result accuracy is:  0.9823\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}